{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW0ya8N2tJDrMZH+2nxy34",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/Article_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vsP11Gk-I02"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp,\n",
        "                                       n_fft=FRAME_SIZE,\n",
        "                                       hop_length=OVERLAP,\n",
        "                                       n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(\n",
        "        mag, n_iter=n_iter,\n",
        "        n_fft=n_fft, hop_length=hop_length\n",
        "    )\n",
        "\n",
        "def reconstruct_with_noisy_phase(lp, noisy_phase,\n",
        "                                 hop_length=OVERLAP):\n",
        "    power = np.exp(np.nan_to_num(lp)) - EPSILON\n",
        "    mag   = np.sqrt(np.clip(power, 0, None))\n",
        "    S     = mag * np.exp(1j * noisy_phase)\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loading ──────────────────────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir,\n",
        "                                      window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for cf in files:\n",
        "            if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "                continue\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace('_clean_logpower_', '_noisy_concat_')\n",
        "            if not os.path.exists(npath):\n",
        "                continue\n",
        "            C = np.load(cpath)  # [129, T]\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]:\n",
        "                continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size - 1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]\n",
        "    Y = np.array(Ys, dtype=np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ── Normalization ────────────────────────────────────────────────────────\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    Xn     = (X - Xm) / Xs\n",
        "    Yn     = (Y - Ym) / Ys\n",
        "    return Xn, Yn, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition ─────────────────────────────────────────────────────\n",
        "class Article2CNN(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1),\n",
        "                               stride=(3,1), padding=(2,0))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        D, T      = input_shape\n",
        "        dummy     = torch.zeros(1,1,D,T)\n",
        "        flat      = self.relu2(\n",
        "                        self.conv2(\n",
        "                          self.relu1(\n",
        "                            self.conv1(dummy)\n",
        "                          )\n",
        "                        )\n",
        "                      ).view(1,-1).size(1)\n",
        "        self.fc1   = nn.Linear(flat, 1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop  = nn.Dropout(0.2)\n",
        "        self.fc2   = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu2(self.conv2(self.relu1(self.conv1(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Evaluation (full‑utterance PESQ/STOI) ─────────────────────────────────\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            continue\n",
        "\n",
        "        # force same length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_wav    /= (np.max(np.abs(clean_wav))    + 1e-12)\n",
        "        enhanced_wav /= (np.max(np.abs(enhanced_wav)) + 1e-12)\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            p = pesq(clean_wav, enhanced_wav, SAMPLE_RATE, 'nb')\n",
        "        except:\n",
        "            p = np.nan\n",
        "        try:\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "        except:\n",
        "            s = np.nan\n",
        "\n",
        "        pesq_scores.append(p)\n",
        "        stoi_scores.append(s)\n",
        "\n",
        "    avg_pesq = np.nanmean(pesq_scores)\n",
        "    avg_stoi = np.nanmean(stoi_scores)\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")\n",
        "\n",
        "# ── Training Loop ─────────────────────────────────────────────────────────\n",
        "def train_and_validate(model,\n",
        "                       train_loader, val_loader,\n",
        "                       train_dir, val_dir,\n",
        "                       Xm, Xs, Ym, Ys,\n",
        "                       num_epochs=50,\n",
        "                       device='cpu',\n",
        "                       patience=5):\n",
        "    crit = nn.MSELoss()\n",
        "    opt  = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    best, stale = float('inf'), 0\n",
        "    train_mse, val_mse, val_pesq, val_stoi = [],[],[],[]\n",
        "\n",
        "    for ep in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        t_loss = 0.0\n",
        "        for bx, by in train_loader:\n",
        "            bx,by = bx.to(device), by.to(device)\n",
        "            opt.zero_grad()\n",
        "            out   = model(bx)\n",
        "            loss  = crit(out, by)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            t_loss += loss.item()*bx.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "        train_mse.append(t_loss)\n",
        "\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for vx, vy in val_loader:\n",
        "                vx,vy = vx.to(device), vy.to(device)\n",
        "                vo    = model(vx)\n",
        "                v_loss+= crit(vo,vy).item()*vx.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "        val_mse.append(v_loss)\n",
        "\n",
        "        p,s = evaluate_on_validation(\n",
        "                  model, train_dir, val_dir,\n",
        "                  WINDOW_SIZE, device, True\n",
        "              )\n",
        "        val_pesq.append(p)\n",
        "        val_stoi.append(s)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: TrainMSE={t_loss:.4f}  \"\n",
        "              f\"ValMSE={v_loss:.4f}  PESQ={p:.3f}  STOI={s:.3f}\")\n",
        "\n",
        "        if v_loss < best:\n",
        "            best, stale = v_loss, 0\n",
        "        else:\n",
        "            stale += 1\n",
        "            if stale >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    return model, train_mse, val_mse, val_pesq, val_stoi\n",
        "\n",
        "# ── Plotting ──────────────────────────────────────────────────────────────\n",
        "def plot_metrics(train_mse, val_mse, val_pesq, val_stoi):\n",
        "    ep = np.arange(1, len(train_mse)+1)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, train_mse, '-o', label='Train MSE')\n",
        "    plt.plot(ep, val_mse,   '-o', label='Val   MSE')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, val_pesq,  '-o', label='Val PESQ')\n",
        "    plt.plot(ep, val_stoi,  '-o', label='Val STOI')\n",
        "    plt.xlabel('Epoch'); plt.legend(); plt.title('Quality')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── Waveform Plots ───────────────────────────────────────────────────────\n",
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for idx, cf in enumerate(samples):\n",
        "        C = np.load(os.path.join(val_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                val_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = (N[:, i-WINDOW_SIZE+1 : i+1] - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Ys) + Ym\n",
        "\n",
        "        clean_wav    = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav    = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase  = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                        ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        t = np.arange(2000) / SAMPLE_RATE\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title); plt.ylim(-1,1)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── WAV Export ───────────────────────────────────────────────────────────\n",
        "def save_enhanced_audio(model, data_dir, out_dir,\n",
        "                        window_size=WINDOW_SIZE,\n",
        "                        device='cpu', num_samples=5,\n",
        "                        Y_mean=0.0, Y_std=1.0):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    allc = [f for f in os.listdir(data_dir)\n",
        "            if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    for cf in random.sample(allc, min(num_samples, len(allc))):\n",
        "        C = np.load(os.path.join(data_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                data_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                        noisy_wav,\n",
        "                        n_fft=FRAME_SIZE,\n",
        "                        hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "\n",
        "        preds = []\n",
        "        for i in range(window_size-1, T):\n",
        "            win = (N[:, i-window_size+1 : i+1] - Y_mean)/Y_std\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Y_std) + Y_mean\n",
        "        if P.shape[1] < T:\n",
        "            P = np.pad(P, ((0,0),(0,T-P.shape[1])), mode='edge')\n",
        "\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(\n",
        "                           P[:N_BINS], noisy_phase[:,:T]\n",
        "                       )\n",
        "\n",
        "        def norm(a):\n",
        "            m = np.max(np.abs(a))\n",
        "            return a/m if m>0 else a\n",
        "\n",
        "        for tag, wav in zip(\n",
        "            ['clean','noisy','enhanced'],\n",
        "            [clean_wav, noisy_wav, enhanced_wav]\n",
        "        ):\n",
        "            wav = norm(wav)\n",
        "            sf.write(\n",
        "                os.path.join(out_dir,\n",
        "                             f\"{tag}_{cf.split('_clean_logpower_')[-1][:-4]}.wav\"),\n",
        "                wav, SAMPLE_RATE\n",
        "            )\n",
        "        print(\"Saved trio:\", cf)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dir = r'C:\\Users\\enhance\\article2_merge\\train'\n",
        "    val_dir   = r'C:\\Users\\enhance\\article2_merge\\val'\n",
        "    test_dir  = r'C:\\Users\\enhance\\article2_merge\\test'\n",
        "\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)),\n",
        "        replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "\n",
        "    Xn_tr,Yn_tr,Xm,Xs,Ym,Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    Xt = torch.from_numpy(Xn_tr).permute(0,3,1,2)\n",
        "    Yt = torch.from_numpy(Yn_tr)\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(Xt, Yt),\n",
        "        batch_size=4, shuffle=True\n",
        "    )\n",
        "\n",
        "    X_val, Y_val = load_article2_dataset_from_merged(val_dir)\n",
        "    Xn_val = (X_val - Xm)/Xs\n",
        "    Yn_val = (Y_val - Ym)/Ys\n",
        "    Xv = torch.from_numpy(Xn_val).permute(0,3,1,2)\n",
        "    Yv = torch.from_numpy(Yn_val)\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(Xv, Yv),\n",
        "        batch_size=4, shuffle=False\n",
        "    )\n",
        "\n",
        "    device = torch.device(\n",
        "        'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    D, T = Xt.shape[2], Xt.shape[3]\n",
        "    model = Article2CNN((D,T)).to(device)\n",
        "\n",
        "    model, train_mse, val_mse, val_pesq, val_stoi = train_and_validate(\n",
        "        model, train_loader, val_loader,\n",
        "        train_dir, val_dir,\n",
        "        Xm, Xs, Ym, Ys,\n",
        "        num_epochs=50, device=device,\n",
        "        patience=5\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_mse, val_mse, val_pesq, val_stoi)\n",
        "    plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device=device)\n",
        "\n",
        "    save_enhanced_audio(\n",
        "        model, test_dir,\n",
        "        r'C:\\Users\\enhance\\article2_test_wavs',\n",
        "        device=device, num_samples=5,\n",
        "        Y_mean=Ym, Y_std=Ys\n",
        "    )\n",
        "\n",
        "    print(\"✅ Done – check plots & test‑WAVs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pesq import pesq as pesq_nb  # Changed from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz (adjusted for your data)\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - enhanced audio too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # force same length and ensure minimum length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        if L < min_len:\n",
        "            print(f\"Skipping {cf} - final length {L} samples too short\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_max = np.max(np.abs(clean_wav))\n",
        "        enh_max = np.max(np.abs(enhanced_wav))\n",
        "\n",
        "        if clean_max < 1e-6 or enh_max < 1e-6:\n",
        "            print(f\"Skipping {cf} - normalization would be unstable\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    /= clean_max\n",
        "        enhanced_wav /= enh_max\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            # Try to compute PESQ even with shorter segments\n",
        "            p = pesq_nb(SAMPLE_RATE, clean_wav, enhanced_wav, 'nb')\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "\n",
        "            # Only append valid scores\n",
        "            if not np.isnan(p) and not np.isnan(s):\n",
        "                pesq_scores.append(p)\n",
        "                stoi_scores.append(s)\n",
        "            else:\n",
        "                print(f\"Skipping {cf} - got NaN scores\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {cf}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Only compute averages if we have valid scores\n",
        "    if len(pesq_scores) > 0 and len(stoi_scores) > 0:\n",
        "        avg_pesq = np.mean(pesq_scores)  # Changed from nanmean since we filtered NaNs\n",
        "        avg_stoi = np.mean(stoi_scores)\n",
        "    else:\n",
        "        print(\"Warning: No valid scores were computed!\")\n",
        "        avg_pesq = float('nan')\n",
        "        avg_stoi = float('nan')\n",
        "\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")"
      ],
      "metadata": {
        "id": "iMYXFVgT_zR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pesq import pesq as pesq_nb  # Changed from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp,\n",
        "                                       n_fft=FRAME_SIZE,\n",
        "                                       hop_length=OVERLAP,\n",
        "                                       n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(\n",
        "        mag, n_iter=n_iter,\n",
        "        n_fft=n_fft, hop_length=hop_length\n",
        "    )\n",
        "\n",
        "def reconstruct_with_noisy_phase(lp, noisy_phase,\n",
        "                                 hop_length=OVERLAP):\n",
        "    power = np.exp(np.nan_to_num(lp)) - EPSILON\n",
        "    mag   = np.sqrt(np.clip(power, 0, None))\n",
        "    S     = mag * np.exp(1j * noisy_phase)\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loading ──────────────────────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir,\n",
        "                                      window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for cf in files:\n",
        "            if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "                continue\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace('_clean_logpower_', '_noisy_concat_')\n",
        "            if not os.path.exists(npath):\n",
        "                continue\n",
        "            C = np.load(cpath)  # [129, T]\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]:\n",
        "                continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size - 1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]\n",
        "    Y = np.array(Ys, dtype=np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ── Normalization ────────────────────────────────────────────────────────\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    Xn     = (X - Xm) / Xs\n",
        "    Yn     = (Y - Ym) / Ys\n",
        "    return Xn, Yn, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition ─────────────────────────────────────────────────────\n",
        "class Article2CNN(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1),\n",
        "                               stride=(3,1), padding=(2,0))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        D, T      = input_shape\n",
        "        dummy     = torch.zeros(1,1,D,T)\n",
        "        flat      = self.relu2(\n",
        "                        self.conv2(\n",
        "                          self.relu1(\n",
        "                            self.conv1(dummy)\n",
        "                          )\n",
        "                        )\n",
        "                      ).view(1,-1).size(1)\n",
        "        self.fc1   = nn.Linear(flat, 1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop  = nn.Dropout(0.2)\n",
        "        self.fc2   = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu2(self.conv2(self.relu1(self.conv1(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Evaluation (full‑utterance PESQ/STOI) ─────────────────────────────────\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz (adjusted for your data)\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - enhanced audio too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # force same length and ensure minimum length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        if L < min_len:\n",
        "            print(f\"Skipping {cf} - final length {L} samples too short\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_max = np.max(np.abs(clean_wav))\n",
        "        enh_max = np.max(np.abs(enhanced_wav))\n",
        "\n",
        "        if clean_max < 1e-6 or enh_max < 1e-6:\n",
        "            print(f\"Skipping {cf} - normalization would be unstable\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    /= clean_max\n",
        "        enhanced_wav /= enh_max\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            # Try to compute PESQ even with shorter segments\n",
        "            p = pesq_nb(SAMPLE_RATE, clean_wav, enhanced_wav, 'nb')\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "\n",
        "            # Only append valid scores\n",
        "            if not np.isnan(p) and not np.isnan(s):\n",
        "                pesq_scores.append(p)\n",
        "                stoi_scores.append(s)\n",
        "            else:\n",
        "                print(f\"Skipping {cf} - got NaN scores\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {cf}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Only compute averages if we have valid scores\n",
        "    if len(pesq_scores) > 0 and len(stoi_scores) > 0:\n",
        "        avg_pesq = np.mean(pesq_scores)  # Changed from nanmean since we filtered NaNs\n",
        "        avg_stoi = np.mean(stoi_scores)\n",
        "    else:\n",
        "        print(\"Warning: No valid scores were computed!\")\n",
        "        avg_pesq = float('nan')\n",
        "        avg_stoi = float('nan')\n",
        "\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")\n",
        "\n",
        "# ── Training Loop ─────────────────────────────────────────────────────────\n",
        "def train_and_validate(model,\n",
        "                       train_loader, val_loader,\n",
        "                       train_dir, val_dir,\n",
        "                       Xm, Xs, Ym, Ys,\n",
        "                       num_epochs=50,\n",
        "                       device='cpu',\n",
        "                       patience=5):\n",
        "    crit = nn.MSELoss()\n",
        "    opt  = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    best, stale = float('inf'), 0\n",
        "    train_mse, val_mse, val_pesq, val_stoi = [],[],[],[]\n",
        "\n",
        "    for ep in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        t_loss = 0.0\n",
        "        for bx, by in train_loader:\n",
        "            bx,by = bx.to(device), by.to(device)\n",
        "            opt.zero_grad()\n",
        "            out   = model(bx)\n",
        "            loss  = crit(out, by)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            t_loss += loss.item()*bx.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "        train_mse.append(t_loss)\n",
        "\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for vx, vy in val_loader:\n",
        "                vx,vy = vx.to(device), vy.to(device)\n",
        "                vo    = model(vx)\n",
        "                v_loss+= crit(vo,vy).item()*vx.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "        val_mse.append(v_loss)\n",
        "\n",
        "        p,s = evaluate_on_validation(\n",
        "                  model, train_dir, val_dir,\n",
        "                  WINDOW_SIZE, device, True\n",
        "              )\n",
        "        val_pesq.append(p)\n",
        "        val_stoi.append(s)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: TrainMSE={t_loss:.4f}  \"\n",
        "              f\"ValMSE={v_loss:.4f}  PESQ={p:.3f}  STOI={s:.3f}\")\n",
        "\n",
        "        if v_loss < best:\n",
        "            best, stale = v_loss, 0\n",
        "        else:\n",
        "            stale += 1\n",
        "            if stale >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    return model, train_mse, val_mse, val_pesq, val_stoi\n",
        "\n",
        "# ── Plotting ──────────────────────────────────────────────────────────────\n",
        "def plot_metrics(train_mse, val_mse, val_pesq, val_stoi):\n",
        "    ep = np.arange(1, len(train_mse)+1)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, train_mse, '-o', label='Train MSE')\n",
        "    plt.plot(ep, val_mse,   '-o', label='Val   MSE')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, val_pesq,  '-o', label='Val PESQ')\n",
        "    plt.plot(ep, val_stoi,  '-o', label='Val STOI')\n",
        "    plt.xlabel('Epoch'); plt.legend(); plt.title('Quality')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── Waveform Plots ───────────────────────────────────────────────────────\n",
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for idx, cf in enumerate(samples):\n",
        "        C = np.load(os.path.join(val_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                val_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = (N[:, i-WINDOW_SIZE+1 : i+1] - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Ys) + Ym\n",
        "\n",
        "        clean_wav    = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav    = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase  = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                        ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        t = np.arange(2000) / SAMPLE_RATE\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title); plt.ylim(-1,1)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── WAV Export ───────────────────────────────────────────────────────────\n",
        "def save_enhanced_audio(model, data_dir, out_dir,\n",
        "                        window_size=WINDOW_SIZE,\n",
        "                        device='cpu', num_samples=5,\n",
        "                        Y_mean=0.0, Y_std=1.0):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    allc = [f for f in os.listdir(data_dir)\n",
        "            if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    for cf in random.sample(allc, min(num_samples, len(allc))):\n",
        "        C = np.load(os.path.join(data_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                data_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                        noisy_wav,\n",
        "                        n_fft=FRAME_SIZE,\n",
        "                        hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "\n",
        "        preds = []\n",
        "        for i in range(window_size-1, T):\n",
        "            win = (N[:, i-window_size+1 : i+1] - Y_mean)/Y_std\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Y_std) + Y_mean\n",
        "        if P.shape[1] < T:\n",
        "            P = np.pad(P, ((0,0),(0,T-P.shape[1])), mode='edge')\n",
        "\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(\n",
        "                           P[:N_BINS], noisy_phase[:,:T]\n",
        "                       )\n",
        "\n",
        "        def norm(a):\n",
        "            m = np.max(np.abs(a))\n",
        "            return a/m if m>0 else a\n",
        "\n",
        "        for tag, wav in zip(\n",
        "            ['clean','noisy','enhanced'],\n",
        "            [clean_wav, noisy_wav, enhanced_wav]\n",
        "        ):\n",
        "            wav = norm(wav)\n",
        "            sf.write(\n",
        "                os.path.join(out_dir,\n",
        "                             f\"{tag}_{cf.split('_clean_logpower_')[-1][:-4]}.wav\"),\n",
        "                wav, SAMPLE_RATE\n",
        "            )\n",
        "        print(\"Saved trio:\", cf)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dir = r'C:\\Users\\enhance\\article2_merge\\train'\n",
        "    val_dir   = r'C:\\Users\\enhance\\article2_merge\\val'\n",
        "    test_dir  = r'C:\\Users\\enhance\\article2_merge\\test'\n",
        "\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)),\n",
        "        replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "\n",
        "    Xn_tr,Yn_tr,Xm,Xs,Ym,Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    Xt = torch.from_numpy(Xn_tr).permute(0,3,1,2)\n",
        "    Yt = torch.from_numpy(Yn_tr)\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(Xt, Yt),\n",
        "        batch_size=4, shuffle=True\n",
        "    )\n",
        "\n",
        "    X_val, Y_val = load_article2_dataset_from_merged(val_dir)\n",
        "    Xn_val = (X_val - Xm)/Xs\n",
        "    Yn_val = (Y_val - Ym)/Ys\n",
        "    Xv = torch.from_numpy(Xn_val).permute(0,3,1,2)\n",
        "    Yv = torch.from_numpy(Yn_val)\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(Xv, Yv),\n",
        "        batch_size=4, shuffle=False\n",
        "    )\n",
        "\n",
        "    device = torch.device(\n",
        "        'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    D, T = Xt.shape[2], Xt.shape[3]\n",
        "    model = Article2CNN((D,T)).to(device)\n",
        "\n",
        "    model, train_mse, val_mse, val_pesq, val_stoi = train_and_validate(\n",
        "        model, train_loader, val_loader,\n",
        "        train_dir, val_dir,\n",
        "        Xm, Xs, Ym, Ys,\n",
        "        num_epochs=15, device=device,\n",
        "        patience=5\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_mse, val_mse, val_pesq, val_stoi)\n",
        "    plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device=device)\n",
        "\n",
        "    save_enhanced_audio(\n",
        "        model, test_dir,\n",
        "        r'C:\\Users\\enhance\\article2_test_wavs',\n",
        "        device=device, num_samples=5,\n",
        "        Y_mean=Ym, Y_std=Ys\n",
        "    )\n",
        "\n",
        "    print(\"✅ Done – check plots & test‑WAVs\")\n"
      ],
      "metadata": {
        "id": "Xy-mW0ACFsXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pesq import pesq as pesq_nb  # Changed from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp,\n",
        "                                       n_fft=FRAME_SIZE,\n",
        "                                       hop_length=OVERLAP,\n",
        "                                       n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(\n",
        "        mag, n_iter=n_iter,\n",
        "        n_fft=n_fft, hop_length=hop_length\n",
        "    )\n",
        "\n",
        "def reconstruct_with_noisy_phase(lp, noisy_phase,\n",
        "                                 hop_length=OVERLAP):\n",
        "    power = np.exp(np.nan_to_num(lp)) - EPSILON\n",
        "    mag   = np.sqrt(np.clip(power, 0, None))\n",
        "    S     = mag * np.exp(1j * noisy_phase)\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loading ──────────────────────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir,\n",
        "                                      window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for cf in files:\n",
        "            if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "                continue\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace('_clean_logpower_', '_noisy_concat_')\n",
        "            if not os.path.exists(npath):\n",
        "                continue\n",
        "            C = np.load(cpath)  # [129, T]\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]:\n",
        "                continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size - 1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]\n",
        "    Y = np.array(Ys, dtype=np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ── Normalization ────────────────────────────────────────────────────────\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    Xn     = (X - Xm) / Xs\n",
        "    Yn     = (Y - Ym) / Ys\n",
        "    return Xn, Yn, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition ─────────────────────────────────────────────────────\n",
        "class Article2CNN(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1),\n",
        "                               stride=(3,1), padding=(2,0))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        D, T      = input_shape\n",
        "        dummy     = torch.zeros(1,1,D,T)\n",
        "        flat      = self.relu2(\n",
        "                        self.conv2(\n",
        "                          self.relu1(\n",
        "                            self.conv1(dummy)\n",
        "                          )\n",
        "                        )\n",
        "                      ).view(1,-1).size(1)\n",
        "        self.fc1   = nn.Linear(flat, 1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop  = nn.Dropout(0.2)\n",
        "        self.fc2   = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu2(self.conv2(self.relu1(self.conv1(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Evaluation (full‑utterance PESQ/STOI) ─────────────────────────────────\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz (adjusted for your data)\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - enhanced audio too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # force same length and ensure minimum length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        if L < min_len:\n",
        "            print(f\"Skipping {cf} - final length {L} samples too short\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_max = np.max(np.abs(clean_wav))\n",
        "        enh_max = np.max(np.abs(enhanced_wav))\n",
        "\n",
        "        if clean_max < 1e-6 or enh_max < 1e-6:\n",
        "            print(f\"Skipping {cf} - normalization would be unstable\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    /= clean_max\n",
        "        enhanced_wav /= enh_max\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            # Try to compute PESQ even with shorter segments\n",
        "            p = pesq_nb(SAMPLE_RATE, clean_wav, enhanced_wav, 'nb')\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "\n",
        "            # Only append valid scores\n",
        "            if not np.isnan(p) and not np.isnan(s):\n",
        "                pesq_scores.append(p)\n",
        "                stoi_scores.append(s)\n",
        "            else:\n",
        "                print(f\"Skipping {cf} - got NaN scores\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {cf}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Only compute averages if we have valid scores\n",
        "    if len(pesq_scores) > 0 and len(stoi_scores) > 0:\n",
        "        avg_pesq = np.mean(pesq_scores)  # Changed from nanmean since we filtered NaNs\n",
        "        avg_stoi = np.mean(stoi_scores)\n",
        "    else:\n",
        "        print(\"Warning: No valid scores were computed!\")\n",
        "        avg_pesq = float('nan')\n",
        "        avg_stoi = float('nan')\n",
        "\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")\n",
        "\n",
        "# ── Training Loop ─────────────────────────────────────────────────────────\n",
        "def train_and_validate(model,\n",
        "                       train_loader, val_loader,\n",
        "                       train_dir, val_dir,\n",
        "                       Xm, Xs, Ym, Ys,\n",
        "                       num_epochs=50,\n",
        "                       device='cpu',\n",
        "                       patience=5):\n",
        "    crit = nn.MSELoss()\n",
        "    opt  = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    best, stale = float('inf'), 0\n",
        "    train_mse, val_mse, val_pesq, val_stoi = [],[],[],[]\n",
        "\n",
        "    for ep in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        t_loss = 0.0\n",
        "        for bx, by in train_loader:\n",
        "            bx,by = bx.to(device), by.to(device)\n",
        "            opt.zero_grad()\n",
        "            out   = model(bx)\n",
        "            loss  = crit(out, by)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            t_loss += loss.item()*bx.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "        train_mse.append(t_loss)\n",
        "\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for vx, vy in val_loader:\n",
        "                vx,vy = vx.to(device), vy.to(device)\n",
        "                vo    = model(vx)\n",
        "                v_loss+= crit(vo,vy).item()*vx.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "        val_mse.append(v_loss)\n",
        "\n",
        "        p,s = evaluate_on_validation(\n",
        "                  model, train_dir, val_dir,\n",
        "                  WINDOW_SIZE, device, True\n",
        "              )\n",
        "        val_pesq.append(p)\n",
        "        val_stoi.append(s)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: TrainMSE={t_loss:.4f}  \"\n",
        "              f\"ValMSE={v_loss:.4f}  PESQ={p:.3f}  STOI={s:.3f}\")\n",
        "\n",
        "        if v_loss < best:\n",
        "            best, stale = v_loss, 0\n",
        "        else:\n",
        "            stale += 1\n",
        "            if stale >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    return model, train_mse, val_mse, val_pesq, val_stoi\n",
        "\n",
        "# ── Plotting ──────────────────────────────────────────────────────────────\n",
        "def plot_metrics(train_mse, val_mse, val_pesq, val_stoi):\n",
        "    ep = np.arange(1, len(train_mse)+1)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, train_mse, '-o', label='Train MSE')\n",
        "    plt.plot(ep, val_mse,   '-o', label='Val   MSE')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, val_pesq,  '-o', label='Val PESQ')\n",
        "    plt.plot(ep, val_stoi,  '-o', label='Val STOI')\n",
        "    plt.xlabel('Epoch'); plt.legend(); plt.title('Quality')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── Waveform Plots ───────────────────────────────────────────────────────\n",
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for idx, cf in enumerate(samples):\n",
        "        C = np.load(os.path.join(val_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                val_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = (N[:, i-WINDOW_SIZE+1 : i+1] - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Ys) + Ym\n",
        "\n",
        "        clean_wav    = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav    = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase  = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                        ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        t = np.arange(2000) / SAMPLE_RATE\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title); plt.ylim(-1,1)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── WAV Export ───────────────────────────────────────────────────────────\n",
        "def save_enhanced_audio(model, data_dir, out_dir,\n",
        "                        window_size=WINDOW_SIZE,\n",
        "                        device='cpu', num_samples=5,\n",
        "                        Y_mean=0.0, Y_std=1.0):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    allc = [f for f in os.listdir(data_dir)\n",
        "            if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    for cf in random.sample(allc, min(num_samples, len(allc))):\n",
        "        C = np.load(os.path.join(data_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                data_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                        noisy_wav,\n",
        "                        n_fft=FRAME_SIZE,\n",
        "                        hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "\n",
        "        preds = []\n",
        "        for i in range(window_size-1, T):\n",
        "            win = (N[:, i-window_size+1 : i+1] - Y_mean)/Y_std\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Y_std) + Y_mean\n",
        "        if P.shape[1] < T:\n",
        "            P = np.pad(P, ((0,0),(0,T-P.shape[1])), mode='edge')\n",
        "\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(\n",
        "                           P[:N_BINS], noisy_phase[:,:T]\n",
        "                       )\n",
        "\n",
        "        def norm(a):\n",
        "            m = np.max(np.abs(a))\n",
        "            return a/m if m>0 else a\n",
        "\n",
        "        for tag, wav in zip(\n",
        "            ['clean','noisy','enhanced'],\n",
        "            [clean_wav, noisy_wav, enhanced_wav]\n",
        "        ):\n",
        "            wav = norm(wav)\n",
        "            sf.write(\n",
        "                os.path.join(out_dir,\n",
        "                             f\"{tag}_{cf.split('_clean_logpower_')[-1][:-4]}.wav\"),\n",
        "                wav, SAMPLE_RATE\n",
        "            )\n",
        "        print(\"Saved trio:\", cf)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dir = r'C:\\Users\\enhance\\article2_merge\\train'\n",
        "    val_dir   = r'C:\\Users\\enhance\\article2_merge\\val'\n",
        "    test_dir  = r'C:\\Users\\enhance\\article2_merge\\test'\n",
        "\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)),\n",
        "        replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "\n",
        "    Xn_tr,Yn_tr,Xm,Xs,Ym,Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    Xt = torch.from_numpy(Xn_tr).permute(0,3,1,2)\n",
        "    Yt = torch.from_numpy(Yn_tr)\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(Xt, Yt),\n",
        "        batch_size=4, shuffle=True\n",
        "    )\n",
        "\n",
        "    X_val, Y_val = load_article2_dataset_from_merged(val_dir)\n",
        "    Xn_val = (X_val - Xm)/Xs\n",
        "    Yn_val = (Y_val - Ym)/Ys\n",
        "    Xv = torch.from_numpy(Xn_val).permute(0,3,1,2)\n",
        "    Yv = torch.from_numpy(Yn_val)\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(Xv, Yv),\n",
        "        batch_size=4, shuffle=False\n",
        "    )\n",
        "\n",
        "    device = torch.device(\n",
        "        'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    D, T = Xt.shape[2], Xt.shape[3]\n",
        "    model = Article2CNN((D,T)).to(device)\n",
        "\n",
        "    model, train_mse, val_mse, val_pesq, val_stoi = train_and_validate(\n",
        "        model, train_loader, val_loader,\n",
        "        train_dir, val_dir,\n",
        "        Xm, Xs, Ym, Ys,\n",
        "        num_epochs=15, device=device,\n",
        "        patience=5\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_mse, val_mse, val_pesq, val_stoi)\n",
        "    plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device=device)\n",
        "\n",
        "    save_enhanced_audio(\n",
        "        model, test_dir,\n",
        "        r'C:\\Users\\enhance\\article2_test_wavs',\n",
        "        device=device, num_samples=5,\n",
        "        Y_mean=Ym, Y_std=Ys\n",
        "    )\n",
        "\n",
        "    print(\"✅ Done – check plots & test‑WAVs\")\n"
      ],
      "metadata": {
        "id": "_sovsH6BG6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pesq import pesq as pesq_nb  # Changed from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Loss Functions ─────────────────────────────────────────────────────────\n",
        "def envelope_loss(S1, S2):\n",
        "    \"\"\"Compute loss on temporal envelopes to help STOI\"\"\"\n",
        "    env1 = torch.sum(torch.abs(S1), dim=1)\n",
        "    env2 = torch.sum(torch.abs(S2), dim=1)\n",
        "    env1 = env1 / (torch.max(env1) + 1e-8)\n",
        "    env2 = env2 / (torch.max(env2) + 1e-8)\n",
        "    return torch.mean((env1 - env2) ** 2)\n",
        "\n",
        "def spectral_loss(S1, S2):\n",
        "    \"\"\"Compute loss on spectral structure to help PESQ\"\"\"\n",
        "    return torch.mean(torch.abs(S1 - S2))\n",
        "\n",
        "class EnhancementLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Convert from log to linear domain\n",
        "        pred_linear = torch.exp(pred)\n",
        "        target_linear = torch.exp(target)\n",
        "\n",
        "        # Spectral loss (helps PESQ)\n",
        "        spec_loss = spectral_loss(pred_linear, target_linear)\n",
        "\n",
        "        # Envelope loss (helps STOI)\n",
        "        env_loss = envelope_loss(pred_linear, target_linear)\n",
        "\n",
        "        # Log-domain loss\n",
        "        log_loss = torch.mean(torch.abs(pred - target))\n",
        "\n",
        "        # Combine losses with weights\n",
        "        total_loss = log_loss + 0.3 * spec_loss + 0.3 * env_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp,\n",
        "                                       n_fft=FRAME_SIZE,\n",
        "                                       hop_length=OVERLAP,\n",
        "                                       n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(\n",
        "        mag, n_iter=n_iter,\n",
        "        n_fft=n_fft, hop_length=hop_length\n",
        "    )\n",
        "\n",
        "def reconstruct_with_noisy_phase(lp, noisy_phase,\n",
        "                                 hop_length=OVERLAP):\n",
        "    power = np.exp(np.nan_to_num(lp)) - EPSILON\n",
        "    mag   = np.sqrt(np.clip(power, 0, None))\n",
        "    S     = mag * np.exp(1j * noisy_phase)\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loading ──────────────────────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir,\n",
        "                                      window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for cf in files:\n",
        "            if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "                continue\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace('_clean_logpower_', '_noisy_concat_')\n",
        "            if not os.path.exists(npath):\n",
        "                continue\n",
        "            C = np.load(cpath)  # [129, T]\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]:\n",
        "                continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size - 1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]\n",
        "    Y = np.array(Ys, dtype=np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ── Normalization ────────────────────────────────────────────────────────\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    Xn     = (X - Xm) / Xs\n",
        "    Yn     = (Y - Ym) / Ys\n",
        "    return Xn, Yn, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition ─────────────────────────────────────────────────────\n",
        "class Article2CNNWithAttention(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.bn1 = nn.BatchNorm2d(129)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1),\n",
        "                              stride=(3,1), padding=(2,0))\n",
        "        self.bn2 = nn.BatchNorm2d(43)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Temporal attention\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(43, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        D, T = input_shape\n",
        "        dummy = torch.zeros(1,1,D,T)\n",
        "        flat = self.relu2(\n",
        "            self.bn2(\n",
        "                self.conv2(\n",
        "                    self.relu1(\n",
        "                        self.bn1(\n",
        "                            self.conv1(dummy)\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ).view(1,-1).size(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(flat, 1024)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with batch norm\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "\n",
        "        # Apply temporal attention\n",
        "        att = self.attention(x)\n",
        "        x = x * att\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.bn3(self.fc1(x)))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Evaluation (full‑utterance PESQ/STOI) ─────────────────────────────────\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz (adjusted for your data)\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - enhanced audio too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # force same length and ensure minimum length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        if L < min_len:\n",
        "            print(f\"Skipping {cf} - final length {L} samples too short\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_max = np.max(np.abs(clean_wav))\n",
        "        enh_max = np.max(np.abs(enhanced_wav))\n",
        "\n",
        "        if clean_max < 1e-6 or enh_max < 1e-6:\n",
        "            print(f\"Skipping {cf} - normalization would be unstable\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    /= clean_max\n",
        "        enhanced_wav /= enh_max\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            # Try to compute PESQ even with shorter segments\n",
        "            p = pesq_nb(SAMPLE_RATE, clean_wav, enhanced_wav, 'nb')\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "\n",
        "            # Only append valid scores\n",
        "            if not np.isnan(p) and not np.isnan(s):\n",
        "                pesq_scores.append(p)\n",
        "                stoi_scores.append(s)\n",
        "            else:\n",
        "                print(f\"Skipping {cf} - got NaN scores\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {cf}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Only compute averages if we have valid scores\n",
        "    if len(pesq_scores) > 0 and len(stoi_scores) > 0:\n",
        "        avg_pesq = np.mean(pesq_scores)  # Changed from nanmean since we filtered NaNs\n",
        "        avg_stoi = np.mean(stoi_scores)\n",
        "    else:\n",
        "        print(\"Warning: No valid scores were computed!\")\n",
        "        avg_pesq = float('nan')\n",
        "        avg_stoi = float('nan')\n",
        "\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")\n",
        "\n",
        "# ── Training Loop ─────────────────────────────────────────────────────────\n",
        "def train_and_validate(model,\n",
        "                      train_loader, val_loader,\n",
        "                      train_dir, val_dir,\n",
        "                      Xm, Xs, Ym, Ys,\n",
        "                      num_epochs=50,\n",
        "                      device='cpu',\n",
        "                      patience=5):\n",
        "    # Use custom loss\n",
        "    crit = EnhancementLoss()\n",
        "\n",
        "    # Lower initial learning rate\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Scheduler based on PESQ and STOI\n",
        "    scheduler = torch.optim.ReduceLROnPlateau(\n",
        "        opt, mode='max',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        verbose=True,\n",
        "        threshold=1e-3\n",
        "    )\n",
        "\n",
        "    best_score = float('-inf')\n",
        "    best_model_state = None\n",
        "    stale = 0\n",
        "    train_loss, val_loss, val_pesq, val_stoi = [], [], [], []\n",
        "\n",
        "    for ep in range(1, num_epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        t_loss = 0.0\n",
        "        for bx, by in train_loader:\n",
        "            bx, by = bx.to(device), by.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(bx)\n",
        "            loss = crit(out, by)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            opt.step()\n",
        "            t_loss += loss.item() * bx.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "        train_loss.append(t_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for vx, vy in val_loader:\n",
        "                vx, vy = vx.to(device), vy.to(device)\n",
        "                vo = model(vx)\n",
        "                v_loss += crit(vo, vy).item() * vx.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "        val_loss.append(v_loss)\n",
        "\n",
        "        # Compute PESQ/STOI\n",
        "        p, s = evaluate_on_validation(\n",
        "            model, train_dir, val_dir,\n",
        "            WINDOW_SIZE, device, True\n",
        "        )\n",
        "        val_pesq.append(p)\n",
        "        val_stoi.append(s)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: TrainLoss={t_loss:.4f}  \"\n",
        "              f\"ValLoss={v_loss:.4f}  PESQ={p:.3f}  STOI={s:.3f}\")\n",
        "\n",
        "        # Use combined metric for scheduling and model selection\n",
        "        current_score = p + s  # Equal weight to PESQ and STOI\n",
        "        scheduler.step(current_score)\n",
        "\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_model_state = {\n",
        "                'epoch': ep,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'pesq': p,\n",
        "                'stoi': s\n",
        "            }\n",
        "            stale = 0\n",
        "        else:\n",
        "            stale += 1\n",
        "            if stale >= patience:\n",
        "                print(f\"Early stopping. Best PESQ: {best_model_state['pesq']:.3f}, \"\n",
        "                      f\"Best STOI: {best_model_state['stoi']:.3f}\")\n",
        "                break\n",
        "\n",
        "    # Restore best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state['model_state_dict'])\n",
        "        print(f\"Restored best model from epoch {best_model_state['epoch']} \"\n",
        "              f\"with PESQ={best_model_state['pesq']:.3f}, \"\n",
        "              f\"STOI={best_model_state['stoi']:.3f}\")\n",
        "\n",
        "    return model, train_loss, val_loss, val_pesq, val_stoi\n",
        "\n",
        "# ── Plotting ──────────────────────────────────────────────────────────────\n",
        "def plot_metrics(train_loss, val_loss, val_pesq, val_stoi):\n",
        "    ep = np.arange(1, len(train_loss)+1)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, train_loss, '-o', label='Train Loss')\n",
        "    plt.plot(ep, val_loss,   '-o', label='Val Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, val_pesq,  '-o', label='Val PESQ')\n",
        "    plt.plot(ep, val_stoi,  '-o', label='Val STOI')\n",
        "    plt.xlabel('Epoch'); plt.legend(); plt.title('Quality')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── Waveform Plots ───────────────────────────────────────────────────────\n",
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for idx, cf in enumerate(samples):\n",
        "        C = np.load(os.path.join(val_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                val_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = (N[:, i-WINDOW_SIZE+1 : i+1] - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Ys) + Ym\n",
        "\n",
        "        clean_wav    = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav    = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase  = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                        ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        t = np.arange(2000) / SAMPLE_RATE\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title); plt.ylim(-1,1)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── WAV Export ───────────────────────────────────────────────────────────\n",
        "def save_enhanced_audio(model, data_dir, out_dir,\n",
        "                        window_size=WINDOW_SIZE,\n",
        "                        device='cpu', num_samples=5,\n",
        "                        Y_mean=0.0, Y_std=1.0):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    allc = [f for f in os.listdir(data_dir)\n",
        "            if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    for cf in random.sample(allc, min(num_samples, len(allc))):\n",
        "        C = np.load(os.path.join(data_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                data_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                        noisy_wav,\n",
        "                        n_fft=FRAME_SIZE,\n",
        "                        hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "\n",
        "        preds = []\n",
        "        for i in range(window_size-1, T):\n",
        "            win = (N[:, i-window_size+1 : i+1] - Y_mean)/Y_std\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Y_std) + Y_mean\n",
        "        if P.shape[1] < T:\n",
        "            P = np.pad(P, ((0,0),(0,T-P.shape[1])), mode='edge')\n",
        "\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(\n",
        "                           P[:N_BINS], noisy_phase[:,:T]\n",
        "                       )\n",
        "\n",
        "        def norm(a):\n",
        "            m = np.max(np.abs(a))\n",
        "            return a/m if m>0 else a\n",
        "\n",
        "        for tag, wav in zip(\n",
        "            ['clean','noisy','enhanced'],\n",
        "            [clean_wav, noisy_wav, enhanced_wav]\n",
        "        ):\n",
        "            wav = norm(wav)\n",
        "            sf.write(\n",
        "                os.path.join(out_dir,\n",
        "                             f\"{tag}_{cf.split('_clean_logpower_')[-1][:-4]}.wav\"),\n",
        "                wav, SAMPLE_RATE\n",
        "            )\n",
        "        print(\"Saved trio:\", cf)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dir = r'C:\\Users\\enhance\\article2_merge\\train'\n",
        "    val_dir   = r'C:\\Users\\enhance\\article2_merge\\val'\n",
        "    test_dir  = r'C:\\Users\\enhance\\article2_merge\\test'\n",
        "\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)),\n",
        "        replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "\n",
        "    Xn_tr,Yn_tr,Xm,Xs,Ym,Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    Xt = torch.from_numpy(Xn_tr).permute(0,3,1,2)\n",
        "    Yt = torch.from_numpy(Yn_tr)\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(Xt, Yt),\n",
        "        batch_size=4, shuffle=True\n",
        "    )\n",
        "\n",
        "    X_val, Y_val = load_article2_dataset_from_merged(val_dir)\n",
        "    Xn_val = (X_val - Xm)/Xs\n",
        "    Yn_val = (Y_val - Ym)/Ys\n",
        "    Xv = torch.from_numpy(Xn_val).permute(0,3,1,2)\n",
        "    Yv = torch.from_numpy(Yn_val)\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(Xv, Yv),\n",
        "        batch_size=4, shuffle=False\n",
        "    )\n",
        "\n",
        "    device = torch.device(\n",
        "        'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    D, T = Xt.shape[2], Xt.shape[3]\n",
        "    # Use the new model with attention\n",
        "    model = Article2CNNWithAttention((D,T)).to(device)\n",
        "\n",
        "    model, train_loss, val_loss, val_pesq, val_stoi = train_and_validate(\n",
        "        model, train_loader, val_loader,\n",
        "        train_dir, val_dir,\n",
        "        Xm, Xs, Ym, Ys,\n",
        "        num_epochs=15, device=device,\n",
        "        patience=5\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_loss, val_loss, val_pesq, val_stoi)\n",
        "    plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device=device)\n",
        "\n",
        "    save_enhanced_audio(\n",
        "        model, test_dir,\n",
        "        r'C:\\Users\\enhance\\article2_test_wavs',\n",
        "        device=device, num_samples=5,\n",
        "        Y_mean=Ym, Y_std=Ys\n",
        "    )\n",
        "\n",
        "    print(\"✅ Done – check plots & test‑WAVs\")"
      ],
      "metadata": {
        "id": "M6zOU4TuJuZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from pystoi import stoi\n",
        "from pesq import pesq as pesq_nb  # Changed from pypesq import pesq\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Loss Functions ─────────────────────────────────────────────────────────\n",
        "def envelope_loss(S1, S2):\n",
        "    \"\"\"Compute loss on temporal envelopes to help STOI\"\"\"\n",
        "    env1 = torch.sum(torch.abs(S1), dim=1)\n",
        "    env2 = torch.sum(torch.abs(S2), dim=1)\n",
        "    env1 = env1 / (torch.max(env1) + 1e-8)\n",
        "    env2 = env2 / (torch.max(env2) + 1e-8)\n",
        "    return torch.mean((env1 - env2) ** 2)\n",
        "\n",
        "def spectral_loss(S1, S2):\n",
        "    \"\"\"Compute loss on spectral structure to help PESQ\"\"\"\n",
        "    return torch.mean(torch.abs(S1 - S2))\n",
        "\n",
        "class EnhancementLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Convert from log to linear domain\n",
        "        pred_linear = torch.exp(pred)\n",
        "        target_linear = torch.exp(target)\n",
        "\n",
        "        # Spectral loss (helps PESQ)\n",
        "        spec_loss = spectral_loss(pred_linear, target_linear)\n",
        "\n",
        "        # Envelope loss (helps STOI)\n",
        "        env_loss = envelope_loss(pred_linear, target_linear)\n",
        "\n",
        "        # Log-domain loss\n",
        "        log_loss = torch.mean(torch.abs(pred - target))\n",
        "\n",
        "        # Combine losses with weights\n",
        "        total_loss = log_loss + 0.3 * spec_loss + 0.3 * env_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp,\n",
        "                                       n_fft=FRAME_SIZE,\n",
        "                                       hop_length=OVERLAP,\n",
        "                                       n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(\n",
        "        mag, n_iter=n_iter,\n",
        "        n_fft=n_fft, hop_length=hop_length\n",
        "    )\n",
        "\n",
        "def reconstruct_with_noisy_phase(lp, noisy_phase,\n",
        "                                 hop_length=OVERLAP):\n",
        "    power = np.exp(np.nan_to_num(lp)) - EPSILON\n",
        "    mag   = np.sqrt(np.clip(power, 0, None))\n",
        "    S     = mag * np.exp(1j * noisy_phase)\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loading ──────────────────────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir,\n",
        "                                      window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for cf in files:\n",
        "            if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "                continue\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace('_clean_logpower_', '_noisy_concat_')\n",
        "            if not os.path.exists(npath):\n",
        "                continue\n",
        "            C = np.load(cpath)  # [129, T]\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]:\n",
        "                continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size - 1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]\n",
        "    Y = np.array(Ys, dtype=np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ── Normalization ────────────────────────────────────────────────────────\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    Xn     = (X - Xm) / Xs\n",
        "    Yn     = (Y - Ym) / Ys\n",
        "    return Xn, Yn, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition ─────────────────────────────────────────────────────\n",
        "class Article2CNNWithAttention(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.bn1 = nn.BatchNorm2d(129)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1),\n",
        "                              stride=(3,1), padding=(2,0))\n",
        "        self.bn2 = nn.BatchNorm2d(43)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Temporal attention\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(43, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        D, T = input_shape\n",
        "        dummy = torch.zeros(1,1,D,T)\n",
        "        flat = self.relu2(\n",
        "            self.bn2(\n",
        "                self.conv2(\n",
        "                    self.relu1(\n",
        "                        self.bn1(\n",
        "                            self.conv1(dummy)\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ).view(1,-1).size(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(flat, 1024)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with batch norm\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "\n",
        "        # Apply temporal attention\n",
        "        att = self.attention(x)\n",
        "        x = x * att\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.bn3(self.fc1(x)))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Evaluation (full‑utterance PESQ/STOI) ─────────────────────────────────\n",
        "def evaluate_on_validation(model,\n",
        "                           train_dir, val_dir,\n",
        "                           window_size=WINDOW_SIZE,\n",
        "                           device='cpu',\n",
        "                           return_avgs=False):\n",
        "    # recompute train‑time stats\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir, window_size)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)), replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "    _,_, Xm, Xs, Ym, Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    # minimum length ≔ 1.5 seconds @ 8 kHz (adjusted for your data)\n",
        "    min_len = int(1.5 * SAMPLE_RATE)\n",
        "\n",
        "    pesq_scores, stoi_scores = [], []\n",
        "\n",
        "    for cf in os.listdir(val_dir):\n",
        "        if not (cf.endswith('.npy') and '_clean_logpower_' in cf):\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, cf)\n",
        "        npath = cpath.replace('_clean_logpower_','_noisy_concat_')\n",
        "        if not os.path.exists(npath):\n",
        "            continue\n",
        "\n",
        "        C = np.nan_to_num(np.load(cpath))  # [129,T]\n",
        "        N = np.nan_to_num(np.load(npath))\n",
        "        T = C.shape[1]\n",
        "        if T < window_size:\n",
        "            continue\n",
        "\n",
        "        # reconstruct clean\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        if len(clean_wav) < min_len or np.std(clean_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # sliding-window predict\n",
        "        preds = []\n",
        "        for i in range(window_size - 1, T):\n",
        "            win = N[:, i-window_size+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "        P = (Pn * Ys) + Ym\n",
        "\n",
        "        # reconstruct noisy-phase baseline\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(noisy_wav,\n",
        "                                            n_fft=FRAME_SIZE,\n",
        "                                            hop_length=OVERLAP))[:N_BINS]\n",
        "\n",
        "        # reconstruct enhanced\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "        if len(enhanced_wav) < min_len or np.std(enhanced_wav) < 1e-4:\n",
        "            print(f\"Skipping {cf} - enhanced audio too short or too quiet\")\n",
        "            continue\n",
        "\n",
        "        # force same length and ensure minimum length\n",
        "        L = min(len(clean_wav), len(enhanced_wav))\n",
        "        if L < min_len:\n",
        "            print(f\"Skipping {cf} - final length {L} samples too short\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    = clean_wav[:L]\n",
        "        enhanced_wav = enhanced_wav[:L]\n",
        "\n",
        "        # normalize both into [-1,1]\n",
        "        clean_max = np.max(np.abs(clean_wav))\n",
        "        enh_max = np.max(np.abs(enhanced_wav))\n",
        "\n",
        "        if clean_max < 1e-6 or enh_max < 1e-6:\n",
        "            print(f\"Skipping {cf} - normalization would be unstable\")\n",
        "            continue\n",
        "\n",
        "        clean_wav    /= clean_max\n",
        "        enhanced_wav /= enh_max\n",
        "\n",
        "        # score\n",
        "        try:\n",
        "            # Try to compute PESQ even with shorter segments\n",
        "            p = pesq_nb(SAMPLE_RATE, clean_wav, enhanced_wav, 'nb')\n",
        "            s = stoi(clean_wav, enhanced_wav, SAMPLE_RATE, False)\n",
        "\n",
        "            # Only append valid scores\n",
        "            if not np.isnan(p) and not np.isnan(s):\n",
        "                pesq_scores.append(p)\n",
        "                stoi_scores.append(s)\n",
        "            else:\n",
        "                print(f\"Skipping {cf} - got NaN scores\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {cf}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Only compute averages if we have valid scores\n",
        "    if len(pesq_scores) > 0 and len(stoi_scores) > 0:\n",
        "        avg_pesq = np.mean(pesq_scores)  # Changed from nanmean since we filtered NaNs\n",
        "        avg_stoi = np.mean(stoi_scores)\n",
        "    else:\n",
        "        print(\"Warning: No valid scores were computed!\")\n",
        "        avg_pesq = float('nan')\n",
        "        avg_stoi = float('nan')\n",
        "\n",
        "    if return_avgs:\n",
        "        return avg_pesq, avg_stoi\n",
        "\n",
        "    print(f\"\\nValidation on {len(pesq_scores)} utts → \"\n",
        "          f\"PESQ {avg_pesq:.3f}, STOI {avg_stoi:.3f}\")\n",
        "\n",
        "# ── Training Loop ─────────────────────────────────────────────────────────\n",
        "def train_and_validate(model,\n",
        "                      train_loader, val_loader,\n",
        "                      train_dir, val_dir,\n",
        "                      Xm, Xs, Ym, Ys,\n",
        "                      num_epochs=50,\n",
        "                      device='cpu',\n",
        "                      patience=5):\n",
        "    # Use custom loss\n",
        "    crit = EnhancementLoss()\n",
        "\n",
        "    # Lower initial learning rate\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Scheduler based on PESQ and STOI\n",
        "    scheduler = ReduceLROnPlateau(\n",
        "        opt, mode='max',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        verbose=True,\n",
        "        threshold=1e-3\n",
        "    )\n",
        "\n",
        "    best_score = float('-inf')\n",
        "    best_model_state = None\n",
        "    stale = 0\n",
        "    train_loss, val_loss, val_pesq, val_stoi = [], [], [], []\n",
        "\n",
        "    for ep in range(1, num_epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        t_loss = 0.0\n",
        "        for bx, by in train_loader:\n",
        "            bx, by = bx.to(device), by.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(bx)\n",
        "            loss = crit(out, by)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            opt.step()\n",
        "            t_loss += loss.item() * bx.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "        train_loss.append(t_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for vx, vy in val_loader:\n",
        "                vx, vy = vx.to(device), vy.to(device)\n",
        "                vo = model(vx)\n",
        "                v_loss += crit(vo, vy).item() * vx.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "        val_loss.append(v_loss)\n",
        "\n",
        "        # Compute PESQ/STOI\n",
        "        p, s = evaluate_on_validation(\n",
        "            model, train_dir, val_dir,\n",
        "            WINDOW_SIZE, device, True\n",
        "        )\n",
        "        val_pesq.append(p)\n",
        "        val_stoi.append(s)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: TrainLoss={t_loss:.4f}  \"\n",
        "              f\"ValLoss={v_loss:.4f}  PESQ={p:.3f}  STOI={s:.3f}\")\n",
        "\n",
        "        # Use combined metric for scheduling and model selection\n",
        "        current_score = p + s  # Equal weight to PESQ and STOI\n",
        "        scheduler.step(current_score)\n",
        "\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_model_state = {\n",
        "                'epoch': ep,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'pesq': p,\n",
        "                'stoi': s\n",
        "            }\n",
        "            stale = 0\n",
        "        else:\n",
        "            stale += 1\n",
        "            if stale >= patience:\n",
        "                print(f\"Early stopping. Best PESQ: {best_model_state['pesq']:.3f}, \"\n",
        "                      f\"Best STOI: {best_model_state['stoi']:.3f}\")\n",
        "                break\n",
        "\n",
        "    # Restore best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state['model_state_dict'])\n",
        "        print(f\"Restored best model from epoch {best_model_state['epoch']} \"\n",
        "              f\"with PESQ={best_model_state['pesq']:.3f}, \"\n",
        "              f\"STOI={best_model_state['stoi']:.3f}\")\n",
        "\n",
        "    return model, train_loss, val_loss, val_pesq, val_stoi\n",
        "\n",
        "# ── Plotting ──────────────────────────────────────────────────────────────\n",
        "def plot_metrics(train_loss, val_loss, val_pesq, val_stoi):\n",
        "    ep = np.arange(1, len(train_loss)+1)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, train_loss, '-o', label='Train Loss')\n",
        "    plt.plot(ep, val_loss,   '-o', label='Val Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, val_pesq,  '-o', label='Val PESQ')\n",
        "    plt.plot(ep, val_stoi,  '-o', label='Val STOI')\n",
        "    plt.xlabel('Epoch'); plt.legend(); plt.title('Quality')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── Waveform Plots ───────────────────────────────────────────────────────\n",
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for idx, cf in enumerate(samples):\n",
        "        C = np.load(os.path.join(val_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                val_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = (N[:, i-WINDOW_SIZE+1 : i+1] - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Ys) + Ym\n",
        "\n",
        "        clean_wav    = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav    = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase  = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                        ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        t = np.arange(2000) / SAMPLE_RATE\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title); plt.ylim(-1,1)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ── WAV Export ───────────────────────────────────────────────────────────\n",
        "def save_enhanced_audio(model, data_dir, out_dir,\n",
        "                        window_size=WINDOW_SIZE,\n",
        "                        device='cpu', num_samples=5,\n",
        "                        Y_mean=0.0, Y_std=1.0):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    allc = [f for f in os.listdir(data_dir)\n",
        "            if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    for cf in random.sample(allc, min(num_samples, len(allc))):\n",
        "        C = np.load(os.path.join(data_dir, cf))\n",
        "        N = np.load(os.path.join(\n",
        "                data_dir,\n",
        "                cf.replace('_clean_logpower_','_noisy_concat_')\n",
        "            ))\n",
        "        T = C.shape[1]\n",
        "\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                        noisy_wav,\n",
        "                        n_fft=FRAME_SIZE,\n",
        "                        hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "\n",
        "        preds = []\n",
        "        for i in range(window_size-1, T):\n",
        "            win = (N[:, i-window_size+1 : i+1] - Y_mean)/Y_std\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "        P = (np.stack(preds, axis=1)*Y_std) + Y_mean\n",
        "        if P.shape[1] < T:\n",
        "            P = np.pad(P, ((0,0),(0,T-P.shape[1])), mode='edge')\n",
        "\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(\n",
        "                           P[:N_BINS], noisy_phase[:,:T]\n",
        "                       )\n",
        "\n",
        "        def norm(a):\n",
        "            m = np.max(np.abs(a))\n",
        "            return a/m if m>0 else a\n",
        "\n",
        "        for tag, wav in zip(\n",
        "            ['clean','noisy','enhanced'],\n",
        "            [clean_wav, noisy_wav, enhanced_wav]\n",
        "        ):\n",
        "            wav = norm(wav)\n",
        "            sf.write(\n",
        "                os.path.join(out_dir,\n",
        "                             f\"{tag}_{cf.split('_clean_logpower_')[-1][:-4]}.wav\"),\n",
        "                wav, SAMPLE_RATE\n",
        "            )\n",
        "        print(\"Saved trio:\", cf)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dir = r'C:\\Users\\enhance\\article2_merge\\train'\n",
        "    val_dir   = r'C:\\Users\\enhance\\article2_merge\\val'\n",
        "    test_dir  = r'C:\\Users\\enhance\\article2_merge\\test'\n",
        "\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(\n",
        "        len(X_tr), size=min(100_000, len(X_tr)),\n",
        "        replace=False\n",
        "    )\n",
        "    X_tr, Y_tr = X_tr[idxs], Y_tr[idxs]\n",
        "\n",
        "    Xn_tr,Yn_tr,Xm,Xs,Ym,Ys = normalize_data(X_tr, Y_tr)\n",
        "\n",
        "    Xt = torch.from_numpy(Xn_tr).permute(0,3,1,2)\n",
        "    Yt = torch.from_numpy(Yn_tr)\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(Xt, Yt),\n",
        "        batch_size=4, shuffle=True\n",
        "    )\n",
        "\n",
        "    X_val, Y_val = load_article2_dataset_from_merged(val_dir)\n",
        "    Xn_val = (X_val - Xm)/Xs\n",
        "    Yn_val = (Y_val - Ym)/Ys\n",
        "    Xv = torch.from_numpy(Xn_val).permute(0,3,1,2)\n",
        "    Yv = torch.from_numpy(Yn_val)\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(Xv, Yv),\n",
        "        batch_size=4, shuffle=False\n",
        "    )\n",
        "\n",
        "    device = torch.device(\n",
        "        'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    D, T = Xt.shape[2], Xt.shape[3]\n",
        "    # Use the new model with attention\n",
        "    model = Article2CNNWithAttention((D,T)).to(device)\n",
        "\n",
        "    model, train_loss, val_loss, val_pesq, val_stoi = train_and_validate(\n",
        "        model, train_loader, val_loader,\n",
        "        train_dir, val_dir,\n",
        "        Xm, Xs, Ym, Ys,\n",
        "        num_epochs=15, device=device,\n",
        "        patience=5\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_loss, val_loss, val_pesq, val_stoi)\n",
        "    plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device=device)\n",
        "\n",
        "    save_enhanced_audio(\n",
        "        model, test_dir,\n",
        "        r'C:\\Users\\enhance\\article2_test_wavs',\n",
        "        device=device, num_samples=5,\n",
        "        Y_mean=Ym, Y_std=Ys\n",
        "    )\n",
        "\n",
        "    print(\"✅ Done – check plots & test‑WAVs\")"
      ],
      "metadata": {
        "id": "ogdZbO1LKZfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_waveforms(model, val_dir, Xm, Xs, Ym, Ys, device='cpu'):\n",
        "    files   = [f for f in os.listdir(val_dir)\n",
        "               if f.endswith('.npy') and '_clean_logpower_' in f]\n",
        "    samples = random.sample(files, min(3, len(files)))\n",
        "    plt.figure(figsize=(12,6))\n",
        "\n",
        "    for idx, cf in enumerate(samples):\n",
        "        # load clean & noisy log‑power\n",
        "        C = np.load(os.path.join(val_dir, cf))                  # [129, T]\n",
        "        N = np.load(os.path.join(val_dir, cf.replace(\n",
        "                '_clean_logpower_','_noisy_concat_')))         # [129, T]\n",
        "        T = C.shape[1]\n",
        "\n",
        "        # sliding‑window predict\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = N[:, i-WINDOW_SIZE+1 : i+1]\n",
        "            win = (win - Xm) / Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()\n",
        "            preds.append(out)\n",
        "\n",
        "        # stack + pad/truncate so we end up with exactly T frames\n",
        "        Pn = np.stack(preds, axis=1)          # shape = (129, T‑WINDOW+1)\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode='edge')\n",
        "        else:\n",
        "            Pn = Pn[:, :T]\n",
        "        P = (Pn * Ys) + Ym                    # back to log‑power domain\n",
        "\n",
        "        # reconstruct waveforms\n",
        "        clean_wav   = reconstruct_waveform_from_logpower(C)\n",
        "        noisy_wav   = reconstruct_waveform_from_logpower(N[:N_BINS])\n",
        "        noisy_phase = np.angle(librosa.stft(\n",
        "                          noisy_wav,\n",
        "                          n_fft=FRAME_SIZE,\n",
        "                          hop_length=OVERLAP\n",
        "                       ))[:N_BINS]\n",
        "        enhanced_wav = reconstruct_with_noisy_phase(P[:N_BINS], noisy_phase)\n",
        "\n",
        "        # time axis for plotting\n",
        "        t = np.arange(len(clean_wav)) / SAMPLE_RATE\n",
        "        t = t[:2000]  # zoom into first 2000 samples\n",
        "\n",
        "        # plot clean, noisy, enhanced\n",
        "        for col, wav, title in zip(\n",
        "            range(3),\n",
        "            [clean_wav, noisy_wav, enhanced_wav],\n",
        "            ['Clean','Noisy','Denoised']\n",
        "        ):\n",
        "            plt.subplot(3,3, idx*3 + col + 1)\n",
        "            plt.plot(t, wav[:2000])\n",
        "            plt.title(title)\n",
        "            plt.ylim(-1,1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "YaUMgtZlnEPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}