{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB1HIk65h9M4DLTkC2uVCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/Article_3_Traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIxPv-J4jlwt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import random\n",
        "import logging\n",
        "\n",
        "# -------------------- Parameters -------------------- #\n",
        "SAMPLE_RATE = 16000  # Target sample rate\n",
        "FRAME_SIZE = 512     # Frame length for STFT\n",
        "OVERLAP = 256        # Hop length for STFT (50% overlap)\n",
        "TARGET_SHAPE = (FRAME_SIZE // 2 + 1, 100)  # (257, 100) - entire spectrogram shape before splitting\n",
        "OUTPUT_DIR = \"processed_data_traffic_article3\"  # Updated output directory for traffic data\n",
        "CLEAN_AUDIO_PATH = r\"C:\\Users\\enhance\\converted_clean_wav\"  # Clean audio folder\n",
        "NOISE_PARENT_DIR = r\"C:\\Users\\enhance\\Downloads\\traffic_noise_wav\" # Updated folder for traffic noise\n",
        "SNR_VALUES = [-5, 0, 5]  # SNR values to process\n",
        "CHECKPOINT_DIR = \"checkpoints_article3\"  # Directory to store checkpoints\n",
        "\n",
        "# Create required directories if they don't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Generic Logging and Checkpointing -------------------- #\n",
        "def setup_logger(log_file=None, level=logging.INFO):\n",
        "    \"\"\"\n",
        "    Set up a logger that logs messages to both the console and an optional file.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(level)\n",
        "\n",
        "    # Clear existing handlers\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    formatter = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')\n",
        "\n",
        "    # Console handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    # File handler if log_file is specified\n",
        "    if log_file:\n",
        "        fh = logging.FileHandler(log_file)\n",
        "        fh.setFormatter(formatter)\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "def checkpoint_exists(checkpoint_path):\n",
        "    \"\"\"Check if a checkpoint file exists.\"\"\"\n",
        "    return os.path.exists(checkpoint_path)\n",
        "\n",
        "def write_checkpoint(checkpoint_path, content=\"done\"):\n",
        "    \"\"\"Write a checkpoint file.\"\"\"\n",
        "    with open(checkpoint_path, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "# Set up logger (logs to both console and 'preprocessing_article3.log')\n",
        "logger = setup_logger(log_file=\"preprocessing_article3.log\", level=logging.INFO)\n",
        "\n",
        "# -------------------- Helper Functions -------------------- #\n",
        "def clear_folder_contents(folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "    else:\n",
        "        for filename in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)  # Remove file\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)  # Remove directory\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to delete {file_path}. Reason: {e}\")\n",
        "    logger.info(f\"Cleared contents of folder: {folder_path}\")\n",
        "\n",
        "def extract_files(parent_dir, extension=\".wav\"):\n",
        "    files = []\n",
        "    for root, dirs, filenames in os.walk(parent_dir):\n",
        "        for file in filenames:\n",
        "            if file.lower().endswith(extension):\n",
        "                files.append(os.path.join(root, file))\n",
        "    logger.info(f\"Found {len(files)} files in {parent_dir}.\")\n",
        "    return files\n",
        "\n",
        "def adjust_shape(array, target_shape):\n",
        "    padded_array = np.zeros(target_shape)\n",
        "    min_rows = min(array.shape[0], target_shape[0])\n",
        "    min_cols = min(array.shape[1], target_shape[1])\n",
        "    padded_array[:min_rows, :min_cols] = array[:min_rows, :min_cols]\n",
        "    return padded_array\n",
        "\n",
        "def mix_clean_noisy(clean_audio, noise_audio, snr_db):\n",
        "    clean_power = np.mean(clean_audio ** 2)\n",
        "    noise_power = np.mean(noise_audio ** 2)\n",
        "    scaling_factor = np.sqrt(clean_power / (noise_power * 10 ** (snr_db / 10)))\n",
        "    noisy_audio = clean_audio + scaling_factor * noise_audio\n",
        "    return noisy_audio\n",
        "\n",
        "def compute_stft_features(audio, frame_size, overlap, sr):\n",
        "    f, t, Zxx = scipy.signal.stft(audio, fs=sr, nperseg=frame_size, noverlap=overlap)\n",
        "    real_part = adjust_shape(np.real(Zxx), TARGET_SHAPE)\n",
        "    imag_part = adjust_shape(np.imag(Zxx), TARGET_SHAPE)\n",
        "    return real_part, imag_part\n",
        "\n",
        "def preprocess_audio(clean_path, noise_path, snr, sr=SAMPLE_RATE):\n",
        "    \"\"\"\n",
        "    Preprocess a clean file with a noise file at a given SNR.\n",
        "    Returns combined clean and noisy STFT features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        clean_audio, _ = librosa.load(clean_path, sr=sr)\n",
        "        noise_audio, _ = librosa.load(noise_path, sr=sr)\n",
        "\n",
        "        # Adjust noise length to match clean length\n",
        "        if len(noise_audio) > len(clean_audio):\n",
        "            start_idx = np.random.randint(0, len(noise_audio) - len(clean_audio))\n",
        "            noise_audio = noise_audio[start_idx:start_idx + len(clean_audio)]\n",
        "        else:\n",
        "            noise_audio = np.pad(noise_audio, (0, len(clean_audio) - len(noise_audio)), mode=\"wrap\")\n",
        "\n",
        "        # Mix clean and noisy audio\n",
        "        noisy_audio = mix_clean_noisy(clean_audio, noise_audio, snr)\n",
        "\n",
        "        # Compute STFT features for clean and noisy audio\n",
        "        clean_real, clean_imag = compute_stft_features(clean_audio, FRAME_SIZE, OVERLAP, sr)\n",
        "        noisy_real, noisy_imag = compute_stft_features(noisy_audio, FRAME_SIZE, OVERLAP, sr)\n",
        "\n",
        "        # Transpose to treat each time frame (column) as an individual sample\n",
        "        clean_real_frames = clean_real.T  # shape: (100, 257)\n",
        "        clean_imag_frames = clean_imag.T  # shape: (100, 257)\n",
        "        noisy_real_frames = noisy_real.T  # shape: (100, 257)\n",
        "        noisy_imag_frames = noisy_imag.T  # shape: (100, 257)\n",
        "\n",
        "        # Concatenate the real and imaginary parts for each frame\n",
        "        combined_clean = np.concatenate([clean_real_frames, clean_imag_frames], axis=-1)  # shape: (100, 514)\n",
        "        combined_noisy = np.concatenate([noisy_real_frames, noisy_imag_frames], axis=-1)  # shape: (100, 514)\n",
        "\n",
        "        return combined_clean, combined_noisy\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in preprocess_audio for clean: {clean_path}, noise: {noise_path}, SNR: {snr} -> {e}\")\n",
        "        return None, None\n",
        "\n",
        "# -------------------- Main Execution -------------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    # Clear output directory\n",
        "    clear_folder_contents(OUTPUT_DIR)\n",
        "\n",
        "    # Extract files\n",
        "    clean_files = extract_files(CLEAN_AUDIO_PATH)\n",
        "    noise_files = extract_files(NOISE_PARENT_DIR)\n",
        "\n",
        "    # Calculate total number of tasks (for progress reporting)\n",
        "    total_tasks = len(clean_files) * len(noise_files) * len(SNR_VALUES)\n",
        "    current_task = 0\n",
        "\n",
        "    logger.info(\"Starting preprocessing of audio files...\")\n",
        "\n",
        "    for clean_file in clean_files:\n",
        "        clean_filename = os.path.basename(clean_file).replace(\".wav\", \"\")\n",
        "        clean_output_dir = os.path.join(OUTPUT_DIR, clean_filename)\n",
        "        os.makedirs(clean_output_dir, exist_ok=True)\n",
        "\n",
        "        for noise_file in noise_files:\n",
        "            noise_filename = os.path.basename(noise_file).replace(\".wav\", \"\")\n",
        "\n",
        "            for snr in SNR_VALUES:\n",
        "                current_task += 1\n",
        "                progress_percent = (current_task / total_tasks) * 100\n",
        "                logger.info(f\"Processing task {current_task} of {total_tasks} ({progress_percent:.2f}%): Clean: {clean_file}, Noise: {noise_file}, SNR: {snr}\")\n",
        "\n",
        "                # Create a unique checkpoint filename for this task\n",
        "                checkpoint_name = f\"{clean_filename}_{noise_filename}_{snr}.chk\"\n",
        "                checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_name)\n",
        "\n",
        "                if checkpoint_exists(checkpoint_path):\n",
        "                    logger.info(f\"Checkpoint exists for task {checkpoint_name}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                combined_clean, combined_noisy = preprocess_audio(clean_file, noise_file, snr)\n",
        "                if combined_clean is None or combined_noisy is None:\n",
        "                    logger.error(f\"Failed processing for Clean: {clean_file}, Noise: {noise_file}, SNR: {snr}\")\n",
        "                    continue\n",
        "\n",
        "                # Save the combined features\n",
        "                clean_combined_file = os.path.join(clean_output_dir, f\"clean_combined_{snr}_{noise_filename}.npy\")\n",
        "                noisy_combined_file = os.path.join(clean_output_dir, f\"noisy_combined_{snr}_{noise_filename}.npy\")\n",
        "\n",
        "                np.save(clean_combined_file, combined_clean)\n",
        "                np.save(noisy_combined_file, combined_noisy)\n",
        "\n",
        "                logger.info(f\"Saved combined STFT features (clean shape: {combined_clean.shape}, noisy shape: {combined_noisy.shape}) for SNR {snr} in {clean_output_dir}.\")\n",
        "                write_checkpoint(checkpoint_path)\n",
        "\n",
        "    logger.info(\"Preprocessing complete.\")\n"
      ]
    }
  ]
}