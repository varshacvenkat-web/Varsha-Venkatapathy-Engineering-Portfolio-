{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+Y7dDHXiLNu/0KvbulMme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/Article_3_Babble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5zqKEclkQaD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import random\n",
        "import logging\n",
        "\n",
        "# -------------------- Parameters -------------------- #\n",
        "SAMPLE_RATE = 16000  # Target sample rate\n",
        "FRAME_SIZE = 512     # Frame length for STFT\n",
        "OVERLAP = 256        # Hop length for STFT (50% overlap)\n",
        "TARGET_SHAPE = (FRAME_SIZE // 2 + 1, 100)  # (257, 100) - entire spectrogram shape before splitting\n",
        "OUTPUT_DIR = \"processed_data_article_3\"\n",
        "CLEAN_AUDIO_PATH = r\"C:\\Users\\enhance\\converted_clean_wav\"  # Clean audio folder\n",
        "NOISE_PARENT_DIR = r\"C:\\Users\\enhance\\Downloads\\all_noises\"\n",
        "CHECKPOINT_DIR = \"checkpoints_article_3\"  # Directory for checkpoint files\n",
        "\n",
        "# Create required directories if they don't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Logging & Checkpointing -------------------- #\n",
        "def setup_logger(log_file=\"preprocessing_article_3.log\", level=logging.INFO):\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(level)\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "    formatter = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "    fh = logging.FileHandler(log_file)\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "    return logger\n",
        "\n",
        "def checkpoint_exists(checkpoint_path):\n",
        "    return os.path.exists(checkpoint_path)\n",
        "\n",
        "def write_checkpoint(checkpoint_path, content=\"done\"):\n",
        "    with open(checkpoint_path, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "logger = setup_logger()\n",
        "\n",
        "# -------------------- Helper Functions -------------------- #\n",
        "def clear_folder_contents(folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "    else:\n",
        "        for filename in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to delete {file_path}. Reason: {e}\")\n",
        "    logger.info(f\"Cleared contents of folder: {folder_path}\")\n",
        "\n",
        "def extract_files(parent_dir, extension=\".wav\"):\n",
        "    files = []\n",
        "    for root, _, filenames in os.walk(parent_dir):\n",
        "        for file in filenames:\n",
        "            if file.lower().endswith(extension):\n",
        "                files.append(os.path.join(root, file))\n",
        "    logger.info(f\"Found {len(files)} files in {parent_dir}.\")\n",
        "    return files\n",
        "\n",
        "def adjust_shape(array, target_shape):\n",
        "    padded_array = np.zeros(target_shape)\n",
        "    min_rows = min(array.shape[0], target_shape[0])\n",
        "    min_cols = min(array.shape[1], target_shape[1])\n",
        "    padded_array[:min_rows, :min_cols] = array[:min_rows, :min_cols]\n",
        "    return padded_array\n",
        "\n",
        "def mix_clean_noisy(clean_audio, noise_audio, snr_db):\n",
        "    clean_power = np.mean(clean_audio ** 2)\n",
        "    noise_power = np.mean(noise_audio ** 2)\n",
        "    scaling_factor = np.sqrt(clean_power / (noise_power * 10 ** (snr_db / 10)))\n",
        "    return clean_audio + scaling_factor * noise_audio\n",
        "\n",
        "def compute_stft_features(audio, frame_size, overlap, sr):\n",
        "    f, t, Zxx = scipy.signal.stft(audio, fs=sr, nperseg=frame_size, noverlap=overlap)\n",
        "    real_part = adjust_shape(np.real(Zxx), TARGET_SHAPE)\n",
        "    imag_part = adjust_shape(np.imag(Zxx), TARGET_SHAPE)\n",
        "    return real_part, imag_part\n",
        "\n",
        "def preprocess_audio(clean_path, noise_path, snr, sr=SAMPLE_RATE):\n",
        "    try:\n",
        "        clean_audio, _ = librosa.load(clean_path, sr=sr)\n",
        "        noise_audio, _ = librosa.load(noise_path, sr=sr)\n",
        "\n",
        "        # Adjust noise length to match clean length\n",
        "        if len(noise_audio) > len(clean_audio):\n",
        "            start_idx = np.random.randint(0, len(noise_audio) - len(clean_audio))\n",
        "            noise_audio = noise_audio[start_idx:start_idx + len(clean_audio)]\n",
        "        else:\n",
        "            noise_audio = np.pad(noise_audio, (0, len(clean_audio) - len(noise_audio)), mode=\"wrap\")\n",
        "\n",
        "        noisy_audio = mix_clean_noisy(clean_audio, noise_audio, snr)\n",
        "        clean_real, clean_imag = compute_stft_features(clean_audio, FRAME_SIZE, OVERLAP, sr)\n",
        "        noisy_real, noisy_imag = compute_stft_features(noisy_audio, FRAME_SIZE, OVERLAP, sr)\n",
        "\n",
        "        # Transpose so each row represents one time frame\n",
        "        clean_real_frames = clean_real.T  # shape: (100, 257)\n",
        "        clean_imag_frames = clean_imag.T  # shape: (100, 257)\n",
        "        noisy_real_frames = noisy_real.T  # shape: (100, 257)\n",
        "        noisy_imag_frames = noisy_imag.T  # shape: (100, 257)\n",
        "\n",
        "        combined_clean = np.concatenate([clean_real_frames, clean_imag_frames], axis=-1)  # shape: (100, 514)\n",
        "        combined_noisy = np.concatenate([noisy_real_frames, noisy_imag_frames], axis=-1)  # shape: (100, 514)\n",
        "        return combined_clean, combined_noisy\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing {clean_path} with {noise_path} at SNR {snr}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# -------------------- Main Execution -------------------- #\n",
        "# Clear output folder contents\n",
        "clear_folder_contents(OUTPUT_DIR)\n",
        "\n",
        "# Extract clean and noise files\n",
        "clean_files = extract_files(CLEAN_AUDIO_PATH)\n",
        "noise_files = extract_files(NOISE_PARENT_DIR)\n",
        "\n",
        "# Determine total number of combinations (each clean x each noise x each SNR)\n",
        "snr_levels = [-5, 0, 5]\n",
        "total_combinations = len(clean_files) * len(noise_files) * len(snr_levels)\n",
        "processed_count = 0\n",
        "\n",
        "logger.info(f\"Starting processing of {total_combinations} total combinations.\")\n",
        "\n",
        "for clean_file in clean_files:\n",
        "    clean_filename = os.path.basename(clean_file).replace(\".wav\", \"\")\n",
        "    clean_output_dir = os.path.join(OUTPUT_DIR, clean_filename)\n",
        "    os.makedirs(clean_output_dir, exist_ok=True)\n",
        "\n",
        "    for noise_file in noise_files:\n",
        "        noise_filename = os.path.basename(noise_file).replace(\".wav\", \"\")\n",
        "\n",
        "        for snr in snr_levels:\n",
        "            checkpoint_file = os.path.join(CHECKPOINT_DIR, f\"{clean_filename}_{noise_filename}_{snr}.chk\")\n",
        "            if checkpoint_exists(checkpoint_file):\n",
        "                logger.info(f\"Checkpoint exists for {clean_filename} with noise {noise_filename} at SNR {snr}. Skipping...\")\n",
        "                processed_count += 1\n",
        "                continue\n",
        "\n",
        "            logger.info(f\"Processing {clean_filename} with {noise_filename} at SNR {snr}.\")\n",
        "            combined_clean, combined_noisy = preprocess_audio(clean_file, noise_file, snr)\n",
        "            if combined_clean is None or combined_noisy is None:\n",
        "                logger.error(f\"Skipping due to error: {clean_filename} with {noise_filename} at SNR {snr}.\")\n",
        "                continue\n",
        "\n",
        "            clean_combined_file = os.path.join(clean_output_dir, f\"clean_combined_{snr}_{noise_filename}.npy\")\n",
        "            noisy_combined_file = os.path.join(clean_output_dir, f\"noisy_combined_{snr}_{noise_filename}.npy\")\n",
        "            np.save(clean_combined_file, combined_clean)\n",
        "            np.save(noisy_combined_file, combined_noisy)\n",
        "            logger.info(f\"Saved combined STFT features for {clean_filename} with {noise_filename} at SNR {snr} in {clean_output_dir}.\")\n",
        "\n",
        "            write_checkpoint(checkpoint_file)\n",
        "            processed_count += 1\n",
        "            progress_percent = (processed_count / total_combinations) * 100\n",
        "            logger.info(f\"Progress: {processed_count}/{total_combinations} ({progress_percent:.2f}%) complete.\")\n",
        "\n",
        "logger.info(\"Processing complete.\")\n"
      ]
    }
  ]
}