{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/article_4_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh_xHU6JK8vt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Parameters\n",
        "sampling_rate = 16000\n",
        "frame_length = 512  # 32 ms at 16 kHz\n",
        "frame_shift = 128   # 8 ms at 16 kHz\n",
        "snr_levels = [-5, 0, 5]  # SNR values in dB\n",
        "clean_data_path = \"/path/to/clean/data/\"  # Example: LibriSpeech clean speech\n",
        "noise_data_path = \"/path/to/noise/data/\"  # Example: noise files\n",
        "\n",
        "# Function to compute Log-Power Spectrum (LPS)\n",
        "def compute_lps(signal, n_fft=512, hop_length=128):\n",
        "    stft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length, window='hann')\n",
        "    magnitude = np.abs(stft) ** 2  # Power spectrum\n",
        "    lps = np.log10(np.maximum(magnitude, 1e-8))  # Avoid log(0)\n",
        "    return lps, stft\n",
        "\n",
        "# Function to add noise at a specified SNR\n",
        "def add_noise(clean_signal, noise_signal, snr):\n",
        "    # Adjust noise to match the desired SNR\n",
        "    clean_rms = np.sqrt(np.mean(clean_signal ** 2))\n",
        "    noise_rms = np.sqrt(np.mean(noise_signal ** 2))\n",
        "    desired_noise_rms = clean_rms / (10 ** (snr / 20))\n",
        "    noise_signal = noise_signal * (desired_noise_rms / noise_rms)\n",
        "    noisy_signal = clean_signal + noise_signal\n",
        "    return noisy_signal\n",
        "\n",
        "# Generate Ideal Ratio Mask (IRM)\n",
        "def generate_irm(clean_stft, noisy_stft):\n",
        "    irm = np.abs(clean_stft) / (np.abs(noisy_stft) + 1e-8)\n",
        "    irm = np.minimum(irm, 1)  # Ensure the mask is within [0, 1]\n",
        "    return irm\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "def preprocess_data(clean_data_path, noise_data_path, snr_levels):\n",
        "    clean_files = os.listdir(clean_data_path)\n",
        "    noise_files = os.listdir(noise_data_path)\n",
        "\n",
        "    for clean_file in clean_files:\n",
        "        # Load clean speech\n",
        "        clean_signal, _ = librosa.load(os.path.join(clean_data_path, clean_file), sr=sampling_rate)\n",
        "        clean_lps, clean_stft = compute_lps(clean_signal)\n",
        "\n",
        "        # Select a random noise file\n",
        "        noise_file = np.random.choice(noise_files)\n",
        "        noise_signal, _ = librosa.load(os.path.join(noise_data_path, noise_file), sr=sampling_rate)\n",
        "\n",
        "        # Trim or pad noise to match clean signal length\n",
        "        if len(noise_signal) < len(clean_signal):\n",
        "            noise_signal = np.tile(noise_signal, int(np.ceil(len(clean_signal) / len(noise_signal))))\n",
        "        noise_signal = noise_signal[:len(clean_signal)]\n",
        "\n",
        "        for snr in snr_levels:\n",
        "            # Add noise at specified SNR\n",
        "            noisy_signal = add_noise(clean_signal, noise_signal, snr)\n",
        "            noisy_lps, noisy_stft = compute_lps(noisy_signal)\n",
        "\n",
        "            # Generate IRM\n",
        "            irm = generate_irm(clean_stft, noisy_stft)\n",
        "\n",
        "            # Normalize the LPS features\n",
        "            noisy_lps_normalized = (noisy_lps - np.mean(noisy_lps)) / np.std(noisy_lps)\n",
        "\n",
        "            # Save preprocessed data\n",
        "            np.savez(f\"preprocessed_snr{snr}_{clean_file.split('.')[0]}.npz\",\n",
        "                     noisy_lps=noisy_lps_normalized, irm=irm)\n",
        "            print(f\"Processed {clean_file} with SNR {snr}\")\n",
        "\n",
        "# Run Preprocessing\n",
        "preprocess_data(clean_data_path, noise_data_path, snr_levels)\n"
      ]
    }
  ]
}
