{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLvAUt8qCNGcN7XrEZ05+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/article2_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pystoi import stoi\n",
        "from pypesq import pesq   # pip install pystoi pypesq\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# ── Constants ─────────────────────────────────────────────────────────────\n",
        "SAMPLE_RATE = 8000\n",
        "FRAME_SIZE  = 256\n",
        "OVERLAP     = 128\n",
        "EPSILON     = 1e-10\n",
        "N_ITER      = 32\n",
        "WINDOW_SIZE = 9\n",
        "N_BINS      = FRAME_SIZE // 2 + 1  # 129\n",
        "\n",
        "# ── Reconstruction Helpers ────────────────────────────────────────────────\n",
        "def reconstruct_waveform_from_logpower(lp, n_fft=FRAME_SIZE, hop_length=OVERLAP, n_iter=N_ITER):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    return librosa.griffinlim(mag,\n",
        "                              n_iter=n_iter,\n",
        "                              n_fft=n_fft,\n",
        "                              hop_length=hop_length)\n",
        "\n",
        "def reconstruct_waveform_using_phase(lp, phase, n_fft=FRAME_SIZE, hop_length=OVERLAP):\n",
        "    lp    = np.nan_to_num(lp)\n",
        "    power = np.exp(lp) - EPSILON\n",
        "    mag   = np.sqrt(np.maximum(power, 0))\n",
        "    Tc    = min(mag.shape[1], phase.shape[1])\n",
        "    S     = mag[:,:Tc] * np.exp(1j*phase[:,:Tc])\n",
        "    return librosa.istft(S, hop_length=hop_length)\n",
        "\n",
        "# ── Data Loader (same as training) ─────────────────────────────────────────\n",
        "def load_article2_dataset_from_merged(merged_dir, window_size=WINDOW_SIZE):\n",
        "    Xs, Ys = [], []\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        cleans = [f for f in files if \"_clean_logpower_\" in f and f.endswith(\".npy\")]\n",
        "        for cf in cleans:\n",
        "            cpath = os.path.join(root, cf)\n",
        "            npath = cpath.replace(\"_clean_logpower_\", \"_noisy_concat_\")\n",
        "            if not os.path.exists(npath): continue\n",
        "            C = np.load(cpath)\n",
        "            N = np.load(npath)\n",
        "            if C.shape[1] != N.shape[1]: continue\n",
        "            T = C.shape[1]\n",
        "            for i in range(window_size-1, T):\n",
        "                Xs.append(N[:, i-window_size+1:i+1])\n",
        "                Ys.append(C[:, i])\n",
        "    X = np.array(Xs, dtype=np.float32)[..., np.newaxis]  # [N,129,9,1]\n",
        "    Y = np.array(Ys, dtype=np.float32)                    # [N,129]\n",
        "    return X, Y\n",
        "\n",
        "def normalize_data(X, Y):\n",
        "    Xm, Xs = X.mean(), X.std()\n",
        "    Ym, Ys = Y.mean(), Y.std()\n",
        "    return (X - Xm)/Xs, (Y - Ym)/Ys, Xm, Xs, Ym, Ys\n",
        "\n",
        "# ── Model Definition (exactly your train‐time architecture) ────────────────\n",
        "class Article2CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # conv layers\n",
        "        self.conv1 = nn.Conv2d(1, 129, kernel_size=(5,1), padding=(2,0))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(129, 43, kernel_size=(5,1), stride=(3,1), padding=(2,0))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # figure out flatten size with a dummy [1,1,129,9]\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1,1, N_BINS, WINDOW_SIZE)\n",
        "            x = self.relu2(self.conv2(self.relu1(self.conv1(dummy))))\n",
        "            flat = x.view(1, -1).size(1)\n",
        "        # FC layers\n",
        "        self.fc1   = nn.Linear(flat, 1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop  = nn.Dropout(0.2)\n",
        "        self.fc2   = nn.Linear(1024, N_BINS)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu2(self.conv2(self.relu1(self.conv1(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ── Validation Routine ────────────────────────────────────────────────────\n",
        "def evaluate_on_validation(model, train_dir, val_dir, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    # 1) Re‑compute train‐time normalization stats *exactly* as you did during training\n",
        "    X_tr, Y_tr = load_article2_dataset_from_merged(train_dir)\n",
        "    idxs = np.random.default_rng(42).choice(len(X_tr),\n",
        "                                            size=min(100_000, len(X_tr)),\n",
        "                                            replace=False)\n",
        "    X_sub, Y_sub = X_tr[idxs], Y_tr[idxs]\n",
        "    _, _, Xm, Xs, Ym, Ys = normalize_data(X_sub, Y_sub)\n",
        "\n",
        "    pesq_scores = []\n",
        "    stoi_scores = []\n",
        "\n",
        "    # 2) Loop over your val files\n",
        "    for fname in os.listdir(val_dir):\n",
        "        if not fname.endswith(\".npy\") or \"_clean_logpower_\" not in fname:\n",
        "            continue\n",
        "        cpath = os.path.join(val_dir, fname)\n",
        "        npath = cpath.replace(\"_clean_logpower_\", \"_noisy_concat_\")\n",
        "        if not os.path.exists(npath): continue\n",
        "\n",
        "        C = np.load(cpath)   # [129, T]\n",
        "        N = np.load(npath)   # [129, T]\n",
        "        T = C.shape[1]\n",
        "        if T < WINDOW_SIZE: continue\n",
        "\n",
        "        # reconstruct “ground‐truth” clean for scoring\n",
        "        clean_wav = reconstruct_waveform_from_logpower(C)\n",
        "\n",
        "        # 3) model inference, frame by frame\n",
        "        preds = []\n",
        "        for i in range(WINDOW_SIZE-1, T):\n",
        "            win = N[:, i-WINDOW_SIZE+1:i+1]\n",
        "            win = (win - Xm)/Xs\n",
        "            inp = torch.from_numpy(win.astype(np.float32))\\\n",
        "                       .unsqueeze(0).unsqueeze(0)\\\n",
        "                       .to(device)               # [1,1,129,9]\n",
        "            with torch.no_grad():\n",
        "                out = model(inp).squeeze(0).cpu().numpy()  # [129]\n",
        "            preds.append(out)\n",
        "        Pn = np.stack(preds, axis=1)   # [129, T−8]\n",
        "        # pad/trim back to length T\n",
        "        if Pn.shape[1] < T:\n",
        "            Pn = np.pad(Pn, ((0,0),(0,T-Pn.shape[1])), mode=\"edge\")\n",
        "        else:\n",
        "            Pn = Pn[:,:T]\n",
        "\n",
        "        # 4) de‐normalize\n",
        "        P = Pn * Ys + Ym    # [129, T]\n",
        "\n",
        "        # 5) grab original noisy phase\n",
        "        temp_noisy = reconstruct_waveform_from_logpower(N)\n",
        "        S_noisy    = librosa.stft(temp_noisy,\n",
        "                                  n_fft=FRAME_SIZE,\n",
        "                                  hop_length=OVERLAP,\n",
        "                                  center=False)[:N_BINS]\n",
        "        phase_noisy = np.angle(S_noisy)\n",
        "\n",
        "        # 6) reconstruct enhanced waveform\n",
        "        enhanced = reconstruct_waveform_using_phase(P, phase_noisy[:,:T])\n",
        "\n",
        "        # 7) score\n",
        "        try:\n",
        "            p = pesq(clean_wav, enhanced, SAMPLE_RATE, 'nb')\n",
        "        except:\n",
        "            p = np.nan\n",
        "        try:\n",
        "            s = stoi(clean_wav, enhanced, SAMPLE_RATE, extended=False)\n",
        "        except:\n",
        "            s = np.nan\n",
        "\n",
        "        pesq_scores.append(p)\n",
        "        stoi_scores.append(s)\n",
        "\n",
        "    # final averages\n",
        "    print(f\"\\nValidated on {len(pesq_scores)} utterances.\")\n",
        "    print(f\" → PESQ = {np.nanmean(pesq_scores):.3f}\")\n",
        "    print(f\" → STOI = {np.nanmean(stoi_scores):.3f}\")\n",
        "\n",
        "# ── Main: load your checkpoint and run ─────────────────────────────────────\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # build & load\n",
        "    model = Article2CNN().to(device)\n",
        "    ckpt  = torch.load(r\"C:\\Users\\enhance\\article2_model_trained.pth\",\n",
        "                       map_location=device)\n",
        "    model.load_state_dict(ckpt)\n",
        "    print(\"✅ Loaded trained weights.\")\n",
        "\n",
        "    # evaluate\n",
        "    evaluate_on_validation(\n",
        "        model,\n",
        "        train_dir=r\"C:\\Users\\enhance\\article2_merge\\train\",\n",
        "        val_dir  =r\"C:\\Users\\enhance\\article2_merge\\val\",\n",
        "        device=device\n",
        "    )\n"
      ],
      "metadata": {
        "id": "LWn4Fs61VQ_u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}