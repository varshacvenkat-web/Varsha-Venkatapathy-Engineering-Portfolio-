{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNQhsS0KqqmqyeMJt9eLyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshacvenkat-web/Varsha-Venkatapathy-Engineering-Portfolio-/blob/main/Machinery_Article_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f708wG7RcQIH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from scipy.signal import stft\n",
        "import logging\n",
        "\n",
        "# -------------------- Parameters -------------------- #\n",
        "SAMPLE_RATE = 16000            # 16 kHz sampling rate\n",
        "FRAME_SIZE = 512               # Frame length for STFT (32 ms)\n",
        "OVERLAP = 256                  # 50% overlap\n",
        "SNR_LEVELS = [0, 10, 20, 30, 40] # SNR values in dB\n",
        "OUTPUT_DIR = \"machinery_article1\"  # Output directory for processed data\n",
        "NOISE_DIR = r\"C:\\Users\\enhance\\Downloads\\Machinerydataset\"  # Directory for noise files\n",
        "NEW_CLEAN_DIR = \"converted_clean_wav\"  # Directory for clean WAV files\n",
        "TARGET_SHAPE = (257, 400)      # Fixed spectrogram dimensions\n",
        "CHECKPOINT_DIR = \"checkpoints\" # Directory to store checkpoint files\n",
        "\n",
        "# Create required directories if they don't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(NEW_CLEAN_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Generic Logging and Checkpointing -------------------- #\n",
        "def setup_logger(log_file=None, level=logging.INFO):\n",
        "    \"\"\"\n",
        "    Set up a logger that logs messages to both the console and an optional file.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(level)\n",
        "\n",
        "    # Clear any existing handlers\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    formatter = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')\n",
        "\n",
        "    # Console handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    # File handler if a log_file is specified\n",
        "    if log_file:\n",
        "        fh = logging.FileHandler(log_file)\n",
        "        fh.setFormatter(formatter)\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "def checkpoint_exists(checkpoint_path):\n",
        "    \"\"\"\n",
        "    Check if a checkpoint file exists.\n",
        "    \"\"\"\n",
        "    return os.path.exists(checkpoint_path)\n",
        "\n",
        "def write_checkpoint(checkpoint_path, content=\"done\"):\n",
        "    \"\"\"\n",
        "    Write a checkpoint file.\n",
        "    \"\"\"\n",
        "    with open(checkpoint_path, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "def remove_checkpoint(checkpoint_path):\n",
        "    \"\"\"\n",
        "    Remove a checkpoint file if it exists.\n",
        "    \"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        os.remove(checkpoint_path)\n",
        "\n",
        "# Set up the logger (logs to both console and a file named 'preprocessing.log')\n",
        "logger = setup_logger(log_file=\"preprocessing.log\", level=logging.INFO)\n",
        "\n",
        "# -------------------- Original Audio Preprocessing Code -------------------- #\n",
        "def normalize_audio(audio):\n",
        "    \"\"\"Normalize audio to have zero mean and unit variance.\"\"\"\n",
        "    return (audio - np.mean(audio)) / np.std(audio)\n",
        "\n",
        "def mix_audio(clean, noise, snr):\n",
        "    \"\"\"Mix clean and noise audio at a specific SNR.\"\"\"\n",
        "    clean_power = np.mean(clean ** 2)\n",
        "    noise_power = np.mean(noise ** 2)\n",
        "    snr_linear = 10 ** (snr / 10)\n",
        "    scaling_factor = np.sqrt(clean_power / (snr_linear * noise_power))\n",
        "    return clean + scaling_factor * noise\n",
        "\n",
        "def find_audio_files(directory, extension=\".wav\"):\n",
        "    \"\"\"Recursively find all audio files with the specified extension.\"\"\"\n",
        "    audio_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(extension):\n",
        "                audio_files.append(os.path.join(root, file))\n",
        "    return audio_files\n",
        "\n",
        "def pad_or_truncate(data, target_shape):\n",
        "    \"\"\"Adjust the data to match target_shape by padding or truncating the time dimension.\"\"\"\n",
        "    target_time_frames = target_shape[1]\n",
        "    current_time_frames = data.shape[1]\n",
        "    if current_time_frames < target_time_frames:\n",
        "        padding = target_time_frames - current_time_frames\n",
        "        data = np.pad(data, ((0, 0), (0, padding)), mode='constant')\n",
        "    elif current_time_frames > target_time_frames:\n",
        "        data = data[:, :target_time_frames]\n",
        "    return data\n",
        "\n",
        "def preprocess_audio(clean_path, noise_files, snr_levels, target_shape, sr=SAMPLE_RATE):\n",
        "    \"\"\"\n",
        "    Preprocess clean and noise audio to generate noisy-clean pairs for each SNR level.\n",
        "    Saves the full spectrogram chunk (257 x 400 x 1) as input and extracts one target frame\n",
        "    (e.g., the middle column) from the clean spectrogram.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert clean audio to WAV if needed\n",
        "        wav_clean_path = os.path.join(NEW_CLEAN_DIR, os.path.basename(clean_path).replace(\".flac\", \".wav\"))\n",
        "        if not os.path.exists(wav_clean_path):\n",
        "            logger.info(f\"Converting FLAC to WAV: {clean_path}\")\n",
        "            clean, _ = librosa.load(clean_path, sr=SAMPLE_RATE)\n",
        "            sf.write(wav_clean_path, clean, SAMPLE_RATE)\n",
        "        else:\n",
        "            logger.info(f\"WAV file already exists: {wav_clean_path}\")\n",
        "\n",
        "        # Load and normalize the clean audio\n",
        "        clean, _ = librosa.load(wav_clean_path, sr=SAMPLE_RATE)\n",
        "        clean = normalize_audio(clean)\n",
        "\n",
        "        for snr in snr_levels:\n",
        "            # Randomly select a noise file\n",
        "            noise_path = np.random.choice(noise_files)\n",
        "            logger.info(f\"Using noise file: {noise_path}\")\n",
        "            noise, _ = librosa.load(noise_path, sr=None)\n",
        "            if sr != SAMPLE_RATE:\n",
        "                noise = librosa.resample(noise, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
        "            noise = normalize_audio(noise)\n",
        "            if len(noise) > len(clean):\n",
        "                start_idx = np.random.randint(0, len(noise) - len(clean))\n",
        "                noise = noise[start_idx:start_idx+len(clean)]\n",
        "            else:\n",
        "                start_idx = np.random.randint(0, len(noise))\n",
        "                noise = np.roll(noise, -start_idx)\n",
        "                noise = np.tile(noise, int(np.ceil(len(clean)/len(noise))))\n",
        "                noise = noise[:len(clean)]\n",
        "\n",
        "            # Mix clean and noise to create noisy audio\n",
        "            noisy = mix_audio(clean, noise, snr)\n",
        "\n",
        "            # Compute STFT for clean and noisy signals\n",
        "            _, _, Zxx_clean = stft(clean, fs=SAMPLE_RATE, nperseg=FRAME_SIZE, noverlap=OVERLAP)\n",
        "            _, _, Zxx_noisy = stft(noisy, fs=SAMPLE_RATE, nperseg=FRAME_SIZE, noverlap=OVERLAP)\n",
        "\n",
        "            # Extract magnitude spectrum (first 257 bins)\n",
        "            clean_mag = np.abs(Zxx_clean)[:257, :]\n",
        "            noisy_mag = np.abs(Zxx_noisy)[:257, :]\n",
        "\n",
        "            # Pad or truncate to have consistent time frames (400)\n",
        "            clean_mag = pad_or_truncate(clean_mag, target_shape)\n",
        "            noisy_mag = pad_or_truncate(noisy_mag, target_shape)\n",
        "\n",
        "            # Add channel dimension: shape (257, 400, 1)\n",
        "            clean_mag = clean_mag[..., np.newaxis]\n",
        "            noisy_mag = noisy_mag[..., np.newaxis]\n",
        "\n",
        "            # Choose one target frame from the clean spectrogram (middle frame)\n",
        "            mid_index = target_shape[1] // 2\n",
        "            target_clean = clean_mag[:, mid_index, :]  # shape (257, 1)\n",
        "\n",
        "            # Save the noisy input and target clean frame.\n",
        "            snr_dir = os.path.join(OUTPUT_DIR, f\"snr_{snr}\")\n",
        "            os.makedirs(snr_dir, exist_ok=True)\n",
        "            base_name = os.path.basename(wav_clean_path).replace(\".wav\", \"\")\n",
        "            noisy_file = os.path.join(snr_dir, f\"{base_name}_noisy.npy\")\n",
        "            target_file = os.path.join(snr_dir, f\"{base_name}_clean.npy\")\n",
        "\n",
        "            logger.info(f\"Saving noisy chunk to: {noisy_file} with shape {noisy_mag.shape}\")\n",
        "            logger.info(f\"Saving target frame to: {target_file} with shape {target_clean.shape}\")\n",
        "            np.save(noisy_file, noisy_mag)\n",
        "            np.save(target_file, target_clean)\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error preprocessing {clean_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# -------------------- Main Execution with Checkpointing and Progress -------------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    # Get all clean and noise files\n",
        "    clean_audio_dir = r\"C:\\Users\\enhance\\Downloads\\dev-clean\"\n",
        "    logger.info(\"Getting all clean audio files...\")\n",
        "    clean_audio_files = find_audio_files(clean_audio_dir, extension=\".flac\")\n",
        "    total_files = len(clean_audio_files)\n",
        "    logger.info(f\"Found {total_files} clean audio files.\")\n",
        "\n",
        "    logger.info(\"Getting all noise files...\")\n",
        "    noise_files = find_audio_files(NOISE_DIR, extension=\".wav\")\n",
        "    logger.info(f\"Found {len(noise_files)} noise files.\")\n",
        "\n",
        "    logger.info(\"Starting preprocessing with fixed shape...\")\n",
        "\n",
        "    # Process each clean audio file with checkpointing and progress reporting\n",
        "    for idx, clean_path in enumerate(clean_audio_files, start=1):\n",
        "        base_name = os.path.basename(clean_path).split('.')[0]\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_DIR, base_name + \".chk\")\n",
        "\n",
        "        progress_percent = (idx / total_files) * 100\n",
        "        logger.info(f\"Processing file {idx} of {total_files} ({progress_percent:.2f}%): {clean_path}\")\n",
        "\n",
        "        if checkpoint_exists(checkpoint_path):\n",
        "            logger.info(f\"Checkpoint exists for {clean_path}. Skipping processing.\")\n",
        "            continue\n",
        "\n",
        "        success = preprocess_audio(clean_path, noise_files, SNR_LEVELS, TARGET_SHAPE)\n",
        "        if not success:\n",
        "            logger.error(f\"Failed to preprocess: {clean_path}\")\n",
        "        else:\n",
        "            logger.info(f\"Successfully preprocessed: {clean_path}\")\n",
        "            write_checkpoint(checkpoint_path)\n",
        "\n",
        "    logger.info(\"Preprocessing complete.\")\n"
      ]
    }
  ]
}
